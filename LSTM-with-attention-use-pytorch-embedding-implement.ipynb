{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load config and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import spacy, pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import random\n",
    "import inspect\n",
    "\n",
    "# Custom impport\n",
    "from common.common_classes import TensorField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.tsv', 'LSTM-with-attention-implement.ipynb', 'prepare-word-embedding-nlp.ipynb', 'LSTM-with-attention-use-pytorch-embedding-implement.ipynb', 'tokenization.ipynb', 'test-batching-padding.ipynb', 'train.tsv', 'test-batching-padding-ok.ipynb', 'LSTM-implement.ipynb', 'sampleSubmission.csv', 'save_data', '.ipynb_checkpoints', '__init__.py', 'README.md', '.gitignore', '.git', 'common', 'simple-GRU-implement.ipynb']\n"
     ]
    }
   ],
   "source": [
    "path = \"./\"\n",
    "save_data_path = path + 'save_data/'\n",
    "large_save_data_path = '/notebooks/large-storage/'\n",
    "saved_models_path = '/notebooks/large-storage/saved-models/'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pickle.load(open(save_data_path + 'pre-processed-data.pkl', 'rb'))\n",
    "loaded_kaggle_test = pickle.load(open(save_data_path + 'pre-processed-kaggle-test.pkl', 'rb'))\n",
    "loaded_vocab = pickle.load(open(save_data_path + 'genereated-vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, a, series, of, escapades, demonstratin...</td>\n",
       "      <td>[2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, a, series, of, escapades, demonstratin...</td>\n",
       "      <td>[2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, a, series, xxeos]</td>\n",
       "      <td>[2, 10, 341, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, a, xxeos]</td>\n",
       "      <td>[2, 10, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, series, xxeos]</td>\n",
       "      <td>[2, 341, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Phrase_length  \\\n",
       "0          1            188   \n",
       "1          2             77   \n",
       "2          2              8   \n",
       "3          2              1   \n",
       "4          2              6   \n",
       "\n",
       "                                    Tokenized_phrase  \\\n",
       "0  [xxbos, a, series, of, escapades, demonstratin...   \n",
       "1  [xxbos, a, series, of, escapades, demonstratin...   \n",
       "2                          [xxbos, a, series, xxeos]   \n",
       "3                                  [xxbos, a, xxeos]   \n",
       "4                             [xxbos, series, xxeos]   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...  \n",
       "1  [2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...  \n",
       "2                                    [2, 10, 341, 3]  \n",
       "3                                         [2, 10, 3]  \n",
       "4                                        [2, 341, 3]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, xxmaj, an, xxeos]</td>\n",
       "      <td>[2, 7, 26, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "\n",
       "   Phrase_length                                   Tokenized_phrase  \\\n",
       "0            188  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "1             77  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "2              8                          [xxbos, xxmaj, an, xxeos]   \n",
       "3              1  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "4              6  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]  \n",
       "1      [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "2                                      [2, 7, 26, 3]  \n",
       "3             [2, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "4                  [2, 2606, 1723, 30, 632, 1041, 3]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n",
    "\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]\n",
    "\n",
    "MAX_LABEL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check max length of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "43802\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_index = -1\n",
    "for i in range(len(loaded_data['Tokenized_phrase'])):\n",
    "    if len(loaded_data['Tokenized_phrase'][i]) > max_len:\n",
    "        max_len = len(loaded_data['Tokenized_phrase'][i])\n",
    "        max_index = i\n",
    "        \n",
    "print(max_len)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "35146\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_index = -1\n",
    "for i in range(len(loaded_kaggle_test['Tokenized_phrase'])):\n",
    "    if len(loaded_kaggle_test['Tokenized_phrase'][i]) > max_len:\n",
    "        max_len = len(loaded_kaggle_test['Tokenized_phrase'][i])\n",
    "        max_index = i\n",
    "        \n",
    "print(max_len)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Encoding and prepraing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(large_save_data_path + 'process-spacy-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0.,\n",
       "       0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[BOS].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp.vocab.get_vector('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890280, 308)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test assigning pytorch embedding with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "embed_weights = torch.tensor(nlp.vocab.vectors.data, dtype=torch.float32)\n",
    "embed_layer = nn.Embedding.from_pretrained(embed_weights, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5439657043933447811\n",
      "row: 1081\n"
     ]
    }
   ],
   "source": [
    "cat_id = nlp.vocab.strings[u'cat']\n",
    "print(f\"ID: {cat_id}\")\n",
    "cat_row = nlp.vocab.vectors.key2row[cat_id]\n",
    "print(f\"row: {cat_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector: [-0.15067   -0.024468  -0.23368   -0.23378   -0.18382    0.32711\n",
      " -0.22084   -0.28777    0.12759    1.1656    -0.64163   -0.098455\n",
      " -0.62397    0.010431  -0.25653    0.31799    0.037779   1.1904\n",
      " -0.17714   -0.2595    -0.31461    0.038825  -0.15713   -0.13484\n",
      "  0.36936   -0.30562   -0.40619   -0.38965    0.3686     0.013963\n",
      " -0.6895     0.004066  -0.1367     0.32564    0.24688   -0.14011\n",
      "  0.53889   -0.80441   -0.1777    -0.12922    0.16303    0.14917\n",
      " -0.068429  -0.33922    0.18495   -0.082544  -0.46892    0.39581\n",
      " -0.13742   -0.35132    0.22223   -0.144     -0.048287   0.3379\n",
      " -0.31916    0.20526    0.098624  -0.23877    0.045338   0.43941\n",
      "  0.030385  -0.013821  -0.093273  -0.18178    0.19438   -0.3782\n",
      "  0.70144    0.16236    0.0059111  0.024898  -0.13613   -0.11425\n",
      " -0.31598   -0.14209    0.028194   0.5419    -0.42413   -0.599\n",
      "  0.24976   -0.27003    0.14964    0.29287   -0.31281    0.16543\n",
      " -0.21045   -0.4408     1.2174     0.51236    0.56209    0.14131\n",
      "  0.092514   0.71396   -0.021051  -0.33704   -0.20275   -0.36181\n",
      "  0.22055   -0.25665    0.28425   -0.16968    0.058029   0.61182\n",
      "  0.31576   -0.079185   0.35538   -0.51236    0.4235    -0.30033\n",
      " -0.22376    0.15223   -0.048292   0.23532    0.46507   -0.67579\n",
      " -0.32905    0.08446   -0.22123   -0.045333   0.34463   -0.1455\n",
      " -0.18047   -0.17887    0.96879   -1.0028    -0.47343    0.28542\n",
      "  0.56382   -0.33211   -0.38275   -0.2749    -0.22955   -0.24265\n",
      " -0.37689    0.24822    0.36941    0.14651   -0.37864    0.31134\n",
      " -0.28449    0.36948   -2.8174    -0.38319   -0.022373   0.56376\n",
      "  0.40131   -0.42131   -0.11311   -0.17317    0.1411    -0.13194\n",
      "  0.18494    0.097692  -0.097341  -0.23987    0.16631   -0.28556\n",
      "  0.0038654  0.53292   -0.32367   -0.38744    0.27011   -0.34181\n",
      " -0.27702   -0.67279   -0.10771   -0.062189  -0.24783   -0.070884\n",
      " -0.20898    0.062404   0.022372   0.13408    0.1305    -0.19546\n",
      " -0.46849    0.77731   -0.043978   0.3827    -0.23376    1.0457\n",
      " -0.14371   -0.3565    -0.080713  -0.31047   -0.57822   -0.28067\n",
      " -0.069678   0.068929  -0.16227   -0.63934   -0.62149    0.11222\n",
      " -0.16969   -0.54637    0.49661    0.46565    0.088294  -0.48496\n",
      "  0.69263   -0.068977  -0.53709    0.20802   -0.42987   -0.11921\n",
      "  0.1174    -0.18443    0.43797   -0.1236     0.3607    -0.19608\n",
      " -0.35366    0.18808   -0.5061     0.14455   -0.024368  -0.10772\n",
      " -0.0115     0.58634   -0.054461   0.0076487 -0.056297   0.27193\n",
      "  0.23096   -0.29296   -0.24325    0.10317   -0.10014    0.7089\n",
      "  0.17402   -0.0037509 -0.46304    0.11806   -0.16457   -0.38609\n",
      "  0.14524    0.098122  -0.12352   -0.1047     0.39047   -0.3063\n",
      " -0.65375   -0.0044248 -0.033876   0.037114  -0.27472    0.0053147\n",
      "  0.30737    0.12528   -0.19527   -0.16461    0.087518  -0.051107\n",
      " -0.16323    0.521      0.10822   -0.060379  -0.71735   -0.064327\n",
      "  0.37043   -0.41054   -0.2728    -0.30217    0.015771  -0.43056\n",
      "  0.35647    0.17188   -0.54598   -0.21541   -0.044889  -0.10597\n",
      " -0.54391    0.53908    0.070938   0.097839   0.097908   0.17805\n",
      "  0.18995    0.49962   -0.18529    0.051234   0.019574   0.24805\n",
      "  0.3144    -0.29304    0.54235    0.46672    0.26017   -0.44705\n",
      "  0.28287   -0.033345  -0.33181   -0.10902   -0.023324   0.2106\n",
      " -0.29633    0.81506    0.038524   0.46004    0.17187   -0.29804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.       ]\n",
      "embedding: tensor([[-0.1507, -0.0245, -0.2337, -0.2338, -0.1838,  0.3271, -0.2208, -0.2878,\n",
      "          0.1276,  1.1656, -0.6416, -0.0985, -0.6240,  0.0104, -0.2565,  0.3180,\n",
      "          0.0378,  1.1904, -0.1771, -0.2595, -0.3146,  0.0388, -0.1571, -0.1348,\n",
      "          0.3694, -0.3056, -0.4062, -0.3896,  0.3686,  0.0140, -0.6895,  0.0041,\n",
      "         -0.1367,  0.3256,  0.2469, -0.1401,  0.5389, -0.8044, -0.1777, -0.1292,\n",
      "          0.1630,  0.1492, -0.0684, -0.3392,  0.1849, -0.0825, -0.4689,  0.3958,\n",
      "         -0.1374, -0.3513,  0.2222, -0.1440, -0.0483,  0.3379, -0.3192,  0.2053,\n",
      "          0.0986, -0.2388,  0.0453,  0.4394,  0.0304, -0.0138, -0.0933, -0.1818,\n",
      "          0.1944, -0.3782,  0.7014,  0.1624,  0.0059,  0.0249, -0.1361, -0.1142,\n",
      "         -0.3160, -0.1421,  0.0282,  0.5419, -0.4241, -0.5990,  0.2498, -0.2700,\n",
      "          0.1496,  0.2929, -0.3128,  0.1654, -0.2104, -0.4408,  1.2174,  0.5124,\n",
      "          0.5621,  0.1413,  0.0925,  0.7140, -0.0211, -0.3370, -0.2027, -0.3618,\n",
      "          0.2206, -0.2567,  0.2842, -0.1697,  0.0580,  0.6118,  0.3158, -0.0792,\n",
      "          0.3554, -0.5124,  0.4235, -0.3003, -0.2238,  0.1522, -0.0483,  0.2353,\n",
      "          0.4651, -0.6758, -0.3291,  0.0845, -0.2212, -0.0453,  0.3446, -0.1455,\n",
      "         -0.1805, -0.1789,  0.9688, -1.0028, -0.4734,  0.2854,  0.5638, -0.3321,\n",
      "         -0.3828, -0.2749, -0.2296, -0.2427, -0.3769,  0.2482,  0.3694,  0.1465,\n",
      "         -0.3786,  0.3113, -0.2845,  0.3695, -2.8174, -0.3832, -0.0224,  0.5638,\n",
      "          0.4013, -0.4213, -0.1131, -0.1732,  0.1411, -0.1319,  0.1849,  0.0977,\n",
      "         -0.0973, -0.2399,  0.1663, -0.2856,  0.0039,  0.5329, -0.3237, -0.3874,\n",
      "          0.2701, -0.3418, -0.2770, -0.6728, -0.1077, -0.0622, -0.2478, -0.0709,\n",
      "         -0.2090,  0.0624,  0.0224,  0.1341,  0.1305, -0.1955, -0.4685,  0.7773,\n",
      "         -0.0440,  0.3827, -0.2338,  1.0457, -0.1437, -0.3565, -0.0807, -0.3105,\n",
      "         -0.5782, -0.2807, -0.0697,  0.0689, -0.1623, -0.6393, -0.6215,  0.1122,\n",
      "         -0.1697, -0.5464,  0.4966,  0.4656,  0.0883, -0.4850,  0.6926, -0.0690,\n",
      "         -0.5371,  0.2080, -0.4299, -0.1192,  0.1174, -0.1844,  0.4380, -0.1236,\n",
      "          0.3607, -0.1961, -0.3537,  0.1881, -0.5061,  0.1445, -0.0244, -0.1077,\n",
      "         -0.0115,  0.5863, -0.0545,  0.0076, -0.0563,  0.2719,  0.2310, -0.2930,\n",
      "         -0.2432,  0.1032, -0.1001,  0.7089,  0.1740, -0.0038, -0.4630,  0.1181,\n",
      "         -0.1646, -0.3861,  0.1452,  0.0981, -0.1235, -0.1047,  0.3905, -0.3063,\n",
      "         -0.6538, -0.0044, -0.0339,  0.0371, -0.2747,  0.0053,  0.3074,  0.1253,\n",
      "         -0.1953, -0.1646,  0.0875, -0.0511, -0.1632,  0.5210,  0.1082, -0.0604,\n",
      "         -0.7174, -0.0643,  0.3704, -0.4105, -0.2728, -0.3022,  0.0158, -0.4306,\n",
      "          0.3565,  0.1719, -0.5460, -0.2154, -0.0449, -0.1060, -0.5439,  0.5391,\n",
      "          0.0709,  0.0978,  0.0979,  0.1780,  0.1900,  0.4996, -0.1853,  0.0512,\n",
      "          0.0196,  0.2481,  0.3144, -0.2930,  0.5423,  0.4667,  0.2602, -0.4471,\n",
      "          0.2829, -0.0333, -0.3318, -0.1090, -0.0233,  0.2106, -0.2963,  0.8151,\n",
      "          0.0385,  0.4600,  0.1719, -0.2980,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# cat_embedding is a Tensor representation of cat_vector\n",
    "cat_vector = nlp.vocab.vectors[cat_id]\n",
    "print(f\"vector: {cat_vector}\")\n",
    "cat_embedding = embed_layer(torch.LongTensor([cat_row]))\n",
    "print(f\"embedding: {cat_embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_embedding.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([890280, 308])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer.weight.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15321870174910142188\n",
      "row: 684831\n"
     ]
    }
   ],
   "source": [
    "pad_id = nlp.vocab.strings[PAD]\n",
    "print(f\"ID: {pad_id}\")\n",
    "pad_row = nlp.vocab.vectors.key2row[pad_id]\n",
    "print(f\"row: {pad_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle Train dataset\n",
    "PHRASE_ID = data.Field(use_vocab = False)\n",
    "TEXT = TensorField(include_lengths = True, use_vocab = False, sequential = False, pad_token = pad_row)\n",
    "LABEL = data.LabelField(use_vocab = False, dtype=torch.long)\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "ID_TEST = data.Field(use_vocab = False)\n",
    "PHRASE_ID_TEST = data.Field(use_vocab = False)\n",
    "TEXT_TEST = TensorField(include_lengths = True, use_vocab = False, sequential = False, pad_token = pad_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle Train dataset\n",
    "fields = [('id', PHRASE_ID), ('text', TEXT), ('label', LABEL)]\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "fields_test = [('id', ID_TEST), ('phrase_id', PHRASE_ID_TEST), ('text', TEXT_TEST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_data['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_kaggle_test['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_rown: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7fa56f5bcdd8>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5bce48>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5bce80>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5bceb8>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5bcef0>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5bcf28>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5bcf60>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5bcf98>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5bcfd0>,\n",
       " <torchtext.data.example.Example at 0x7fa56f5b6048>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unknown row\n",
    "unknown_id = nlp.vocab.strings[UNK]\n",
    "unknown_row = nlp.vocab.vectors.key2row[unknown_id]\n",
    "print(f\"unknown_rown: {unknown_row}\")\n",
    "\n",
    "# For Kaggle Train dataset\n",
    "examples = []\n",
    "length = len(loaded_data['Phrase'])\n",
    "for i in range(length):\n",
    "    indexes = []\n",
    "    for j in range(len(loaded_data['Tokenized_phrase'][i])):\n",
    "        if nlp.vocab.has_vector(loaded_data['Tokenized_phrase'][i][j]):\n",
    "            token_id = nlp.vocab.strings[loaded_data['Tokenized_phrase'][i][j]]\n",
    "            token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "\n",
    "            indexes.append(token_row)\n",
    "        else:\n",
    "            indexes.append(unknown_row)\n",
    "    \n",
    "    examples.append(data.Example.fromlist([ [loaded_data['PhraseId'][i]], indexes, loaded_data['Sentiment'][i]], fields))\n",
    "    \n",
    "examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_rown: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7fa4dacf9908>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf98d0>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf99b0>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf9a20>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf99e8>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf9a58>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf9ac8>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf9b38>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf9b70>,\n",
       " <torchtext.data.example.Example at 0x7fa4dacf9ba8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unknown row\n",
    "unknown_id = nlp.vocab.strings[UNK]\n",
    "unknown_row = nlp.vocab.vectors.key2row[unknown_id]\n",
    "print(f\"unknown_rown: {unknown_row}\")\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "examples_test = []\n",
    "length = len(loaded_kaggle_test['Phrase'])\n",
    "for i in range(length):\n",
    "    indexes = []\n",
    "    for j in range(len(loaded_kaggle_test['Tokenized_phrase'][i])):\n",
    "        if nlp.vocab.has_vector(loaded_kaggle_test['Tokenized_phrase'][i][j]):\n",
    "            token_id = nlp.vocab.strings[loaded_kaggle_test['Tokenized_phrase'][i][j]]\n",
    "            token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "            \n",
    "            indexes.append(token_row)\n",
    "        else:\n",
    "            indexes.append(unknown_row)\n",
    "    \n",
    "    examples_test.append(data.Example.fromlist([ [i], [loaded_kaggle_test['PhraseId'][i]], indexes ], fields_test))\n",
    "    \n",
    "examples_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[684832, 6, 684833]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 684833\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings[EOS]\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[684832, 40929, 11176, 29, 737, 3812, 1240, 684833]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_test[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 737\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings['mostly']\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[3].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data.Dataset(examples, fields)\n",
    "data_set_test = data.Dataset(examples_test, fields_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.sort_key = lambda x: len(x.text)\n",
    "data_set_test.sort_key = lambda x: len(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 9131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data_set.split([0.8, 0.1, 0.1], random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sort_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124848"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_set.sort_key = lambda x: len(x.text)\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsource(train_data.sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_set_test.sort_key = lambda x: len(x.text)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsource(data_set_test.sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)\n",
    "\n",
    "kaggle_test_iterator = data.BucketIterator(\n",
    "    data_set_test, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_iterator = iter(train_iterator)\n",
    "batch = next(raw_train_iterator)\n",
    "\n",
    "raw_kaggle_test_iterator = iter(kaggle_test_iterator)\n",
    "batch_test = next(raw_kaggle_test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = batch.text\n",
    "\n",
    "c, d = batch_test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 9])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[684832,    200,     63,     90,      6, 333750,      8,  87261, 684833],\n",
       "        [684832,      6,    176,     42,    313,   2358,   4023,   1214, 684833],\n",
       "        [684832,      3,    141,    253,      6,   1889,    498,      2, 684833],\n",
       "        [684832,    205,     56,     45,    181,   2593,   5716,  10983, 684833],\n",
       "        [684832,    622,    891,     13,      3,     99,      2,   1864, 684833],\n",
       "        [684832,     40,      2,    631,    354,      2,  16439,    810, 684833],\n",
       "        [684832,      5,     23,      6, 684837,    186, 684837,  78888, 684833],\n",
       "        [684832,    308,    407,   2325,      3,   2105,      8,   3242, 684833],\n",
       "        [684832,   3868,    362,    495,    169,      3,    226,  33789, 684833],\n",
       "        [684832,   4407,     13,     58,  12745,    239,      8,  12965, 684833],\n",
       "        [684832,  12657,     13,     36,     94,   2996,     36,  60409, 684833],\n",
       "        [684832,     13,   1321,    495,     29,    371,      3,   2181, 684833],\n",
       "        [684832,     11,      2,      5,     75,   1274,     42,    247, 684833],\n",
       "        [684832,     13,      6,   1843,    641,    506,      8,     81, 684833],\n",
       "        [684832,    282,     57,    380,      2,     29,     39,   4727, 684833],\n",
       "        [684832,      6,  11738,      8,    528,     45,  20602,     10, 684833],\n",
       "        [684832,     76,      6,   1695,      2,  87239,    173,      1, 684833],\n",
       "        [684832,    108,     43,      3,  24748,   2957,   1592,    641, 684833],\n",
       "        [684832,    124,    201,     28,    100,     16,      6,    195, 684833],\n",
       "        [684832,  27607,      2, 640808,    569,      7,   4809,   9103, 684833],\n",
       "        [684832,     79,   1270, 684837,  29162, 684837,  29034,   1198, 684833],\n",
       "        [684832,     24,      6, 684837, 660487, 684837,  73780,   1910, 684833],\n",
       "        [684832,      3,    202,    864,     33,    309,     33,  24733, 684833],\n",
       "        [684832,      3,   3233,     42,     93,    227,   2215,    675, 684833],\n",
       "        [684832,     43,     10,     88,     15,    125,    249,    229, 684833],\n",
       "        [684832,      0, 684837,  30655,      7, 684837, 467330,      0, 684833],\n",
       "        [684832,      3,   2175,  13465, 519081,      8, 684837,  15900, 684833],\n",
       "        [684832,     14,   3535,    216,      7,    412,      6,    176, 684833],\n",
       "        [684832,      6,  22996,      2,   2678,     33,    929,    682, 684833],\n",
       "        [684832, 684837,  21149, 684837,  37420,      7,  11662,   3744, 684833],\n",
       "        [684832,     70,    133, 684837,  18291,    208,      5,    229, 684833],\n",
       "        [684832,     76,     28,  11341,      6,    469,     91,   1198, 684833],\n",
       "        [684832,  44940,     75,  28321,   2467,     33,  18160,   2996, 684833],\n",
       "        [684832,      3,  14074, 294749,      8,      3,   2181,   1905, 684833],\n",
       "        [684832,     23,  13370,     60,     13, 684837,  14378,      7, 684833],\n",
       "        [684832, 684837,      7,  21271,     12,    672,   7635,    772, 684833],\n",
       "        [684832,    214,      3,  30324,      8,  86385,      7,  19761, 684833],\n",
       "        [684832,    111,    510,    472,      5,     19,    293,     10, 684833],\n",
       "        [684832, 684837,     37, 684837,      3, 684837,  82364,   1107, 684833],\n",
       "        [684832, 555441,     68,    245,     31,    498,     54,    239, 684833],\n",
       "        [684832,   3289,      5,      3,   1406,     33,   5960,   2274, 684833],\n",
       "        [684832,    238,  11506,    171,    290,     33,   3693,   3289, 684833],\n",
       "        [684832,  53225,     33,    264, 684837,   6391, 684837, 292733, 684833],\n",
       "        [684832,  99259,    136,    121,      3,    915,    111,   7968, 684833],\n",
       "        [684832,      5, 111434,     12,  10228,     24,   1277, 312845, 684833],\n",
       "        [684832,      6,    649,      2,    354,  46898,    898,      1, 684833],\n",
       "        [684832,     12,     14,   2467,  17537,   1681,     42,    202, 684833],\n",
       "        [684832, 684837, 145780,      7, 684837, 174587, 684837, 139289, 684833],\n",
       "        [684832,      5,      3,  51783,    610,     14,  12530,      7, 684833],\n",
       "        [684832, 684837,  21232,    498,   1235,     56,     45,    569, 684833],\n",
       "        [684832,    244,     62,     14,   3477,     16,   1438,      7, 684833],\n",
       "        [684832,      5,    103,      6,    498,     24,    171,   1065, 684833],\n",
       "        [684832,     23,     13,    379,   2158,     80, 684837,   7124, 684833],\n",
       "        [684832, 684837,    334,   2861,    293,    214,   2446,   2639, 684833],\n",
       "        [684832,      3,    346,      8, 684837,   2084, 684837,   2954, 684833],\n",
       "        [684832,   1865,      5,      3,   8866,   4861,   3724,      1, 684833],\n",
       "        [684832,    141,     91,     33,  12351,    354,  29906,   3974, 684833],\n",
       "        [684832,     14,   3908,      5, 684837,   3561, 684837,  11662, 684833],\n",
       "        [684832,     26,      6,   1202,      7,  43402,    449,     74, 684833],\n",
       "        [684832,   7357,      7,    141,  21340,    498,     13,    178, 684833],\n",
       "        [684832,     16, 684837,   1136, 684837, 140557,     14,   1505, 684833],\n",
       "        [684832,     12,     46,     23,    342,     13, 684837,  59542, 684833],\n",
       "        [684832,     14,     28,    112,     94,      8,    194,      1, 684833],\n",
       "        [684832,     11,    157,      5,    541,   5238,    111,   6234, 684833]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 0, 2, 2, 1, 3, 3, 1, 3, 3, 2, 2, 2, 2, 2, 0, 2, 1, 4, 3, 2, 3, 2,\n",
       "        2, 2, 1, 3, 1, 2, 2, 1, 3, 1, 2, 2, 1, 4, 2, 3, 2, 3, 2, 2, 1, 4, 2, 2,\n",
       "        2, 3, 2, 3, 1, 2, 2, 3, 4, 2, 2, 4, 2, 2, 1, 4], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[133918,  57783,  94049,  86671,  84086,  74128, 112683, 126943,  12599,\n",
       "         138419,  47937,  62635, 104584,  86587, 113162,  81036,  62472, 147974,\n",
       "          32209, 133654,  95241, 137072,  66415,  75555,  53039, 130485,  79837,\n",
       "         152257,  39951, 136680, 121126, 102615, 101662, 119728, 108929, 145776,\n",
       "          36689,  66928, 109732, 109843, 130506,  33026, 123268, 155495, 114095,\n",
       "          27453, 122599,  82520,  21535, 104973,  91096,  97182,  84542, 119081,\n",
       "         104435,  65401,  30863, 141808,  39997, 145932,  46149, 125167, 132902,\n",
       "         117864]], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['Sentiment'][17921-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[684832,    858,     37,     10,     14,    117,      5,     23,    191,\n",
       "         684833],\n",
       "        [684832, 684837,     16, 684837, 146405, 684837,  11721,     92,      1,\n",
       "         684833],\n",
       "        [684832,     19,     16,      3,    420,  20523,      8,     85,    711,\n",
       "         684833],\n",
       "        [684832, 130283,      9,     78,    418,    154,     10,     14,   4905,\n",
       "         684833],\n",
       "        [684832, 684837,   4628,     76,      6,    127,      5, 298172,      2,\n",
       "         684833],\n",
       "        [684832,     36,    194,     63,     90,  12832,     13,      6,  24748,\n",
       "         684833],\n",
       "        [684832,   4089,   5529,      7,    588,     33,  34423,   4043,   2809,\n",
       "         684833],\n",
       "        [684832,    171,    227,  43211,      2,  97814,     33,  98296,  15611,\n",
       "         684833],\n",
       "        [684832,      8, 684837,   7078,    213,  36288,     24,    334,     99,\n",
       "         684833],\n",
       "        [684832,  38669,  13120,      8,     51,   8953,     33,   2467,  58039,\n",
       "         684833],\n",
       "        [684832,      6,  49071,   2076,  13327,      7,   2642,    898,      2,\n",
       "         684833],\n",
       "        [684832,  42793,   7635,    772,  43571,   7635,    772,  21192,  15966,\n",
       "         684833],\n",
       "        [684832,  35010,     13,      3,   3770,      8,  33096, 684837,  19642,\n",
       "         684833],\n",
       "        [684832,    216,    983,      5,    100,     10,   1257,     36,   7540,\n",
       "         684833],\n",
       "        [684832, 684837,    254,     39,   1493,   3592,   7049,  38826,  61157,\n",
       "         684833],\n",
       "        [684832,     42,      3,   5915,  75364,      7,  33060,  22935,   1931,\n",
       "         684833],\n",
       "        [684832, 684837,      3, 684837,      0,  15319,  29798,      2,     29,\n",
       "         684833],\n",
       "        [684832, 684837,  20842,     64, 684837, 150812,   2289, 684837,  23085,\n",
       "         684833],\n",
       "        [684832,      2,  44484,      2, 106919,      2,      7,    557,    789,\n",
       "         684833],\n",
       "        [684832,      3,   4337,   1564,   5279, 684837,  84870, 684837,      0,\n",
       "         684833],\n",
       "        [684832,     63,   1195,     90,    106,   2325,   1120,    111,    309,\n",
       "         684833],\n",
       "        [684832,     23,    407, 684837,   2441, 684837,   4623, 684837,  14615,\n",
       "         684833],\n",
       "        [684832, 684837, 138017, 684837, 331965,     14,   1249,  23325,   1716,\n",
       "         684833],\n",
       "        [684832,    126,    132,     33,    187,      2,    569,      7,   3535,\n",
       "         684833],\n",
       "        [684832,     92,    248,     57,      3,   3883,      8,      6,  48980,\n",
       "         684833],\n",
       "        [684832,     35,     25,     15,    100,   4098,     37,     12,    749,\n",
       "         684833],\n",
       "        [684832,    275,    655,      3,    373,      8,      3,   2527, 106382,\n",
       "         684833],\n",
       "        [684832,     24,   1270,    645,  36343,      7,  14416,   2446,  20055,\n",
       "         684833],\n",
       "        [684832,     27,     38,    526,    216,      5,    100,      6,  23700,\n",
       "         684833],\n",
       "        [684832,      9,    111,  17343,   6345, 684837,      3, 684837,   1907,\n",
       "         684833],\n",
       "        [684832,     36,     70,    201,     23,    618,     13,  29399,  41423,\n",
       "         684833],\n",
       "        [684832, 684837,    305,      9,    997,     48,     10,     13,  21183,\n",
       "         684833],\n",
       "        [684832,     80,      3,    257,      8, 684837,  51012, 684837,   2571,\n",
       "         684833],\n",
       "        [684832, 684837,     59,    582,      5, 684837,  15335,   7311,     18,\n",
       "         684833],\n",
       "        [684832, 684837,    377, 684837,  21790,   6456,     13,  29153,  45137,\n",
       "         684833],\n",
       "        [684832,    100,     13,      3,   2486,      8,    208,     69,     91,\n",
       "         684833],\n",
       "        [684832,     65,     11,     15,      6,  17521,    751,    142,      1,\n",
       "         684833],\n",
       "        [684832, 581431,      3,   1198,     57,      3,    126,   1448,     74,\n",
       "         684833],\n",
       "        [684832,     23,      6,     91,    447,     33,    777,    112,    207,\n",
       "         684833],\n",
       "        [684832,      5,   3922,     57,     39,  10914,     72,    449,   2957,\n",
       "         684833],\n",
       "        [684832,    187,    280,      6,    775,   2747,     13,     93,   6291,\n",
       "         684833],\n",
       "        [684832,  20423,    500,    121,     54,   2072,     33,   2400,   3613,\n",
       "         684833],\n",
       "        [684832,   2357,  11236,    451,    111,    868,      5,      3,    910,\n",
       "         684833],\n",
       "        [684832, 684837,     10,  28157,      5,     23,      6,    200,    224,\n",
       "         684833],\n",
       "        [684832,      6,  13897,     13,      6,   5776,     24,    116,  14766,\n",
       "         684833],\n",
       "        [684832,    588,     33,  47452,   7142,  80686,  39375,     33,  39375,\n",
       "         684833],\n",
       "        [684832,     80,   7854,  24495,      3,    996,      8,    404,  43102,\n",
       "         684833],\n",
       "        [684832,      2,    112,   1669,      2,      7,   2845,   1334,      1,\n",
       "         684833],\n",
       "        [684832,     11,  19429,     36,    132,     36,    221,     33,  11053,\n",
       "         684833],\n",
       "        [684832,      6,   4171,      8,  18108, 153540,      7,   4132,  54142,\n",
       "         684833],\n",
       "        [684832,     24, 684837, 177229,     13,  12311,     14, 684837,    940,\n",
       "         684833],\n",
       "        [684832,      8, 684837,   3561,    905,     13,     58,  28836,    110,\n",
       "         684833],\n",
       "        [684832,    235,      3,    498,      6,  21062,      7,   4285,   5720,\n",
       "         684833],\n",
       "        [684832,      9,     71,    633,     31,   5465,     33,  11233,  23961,\n",
       "         684833],\n",
       "        [684832,   1163,   3862,     77,     10,     14,      6,  20276,   1197,\n",
       "         684833],\n",
       "        [684832, 684837,  37903, 684837,  27644,     76,      6,  84051,  19804,\n",
       "         684833],\n",
       "        [684832,      0,     14,    885,      5,   8041,   8630,      7,    356,\n",
       "         684833],\n",
       "        [684832,     26,  80910,   4861,      7,    377,      8,  95862,   2327,\n",
       "         684833],\n",
       "        [684832,      3,  78776,      8,      3,    770,     33,   5742,    610,\n",
       "         684833],\n",
       "        [684832, 684837,     10,     14,   2662, 173886,     51,      3,    110,\n",
       "         684833],\n",
       "        [684832, 684837,    195,      3,   1198,  79457,     42,    190,    373,\n",
       "         684833],\n",
       "        [684832,     12,     97,     79,    245,    688,     60,      3,    332,\n",
       "         684833],\n",
       "        [684832, 684837,      3,   1198,    235,      6,  10348,   1481,     64,\n",
       "         684833],\n",
       "        [684832,      9,     71,     28,    121,      3, 684837,   2687,   4499,\n",
       "         684833]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[47179, 50045, 46462, 44533, 53032, 32955, 11623, 20504, 41241,  8410,\n",
       "          1622,  7377, 56392, 57556, 12486, 25215, 48991,  3850, 42415, 49212,\n",
       "         59154,  2684, 52932, 62381, 26115, 65211, 63658, 28986, 15879, 58026,\n",
       "         27986, 41181, 46849, 18459, 54574, 46478, 58239, 14695, 30341, 25839,\n",
       "         59208, 35617, 58876, 56748, 17563, 58062,  6787, 22929, 23357, 17287,\n",
       "          4608, 27127, 53929, 65272, 51887, 37848,  3149, 32164, 43127, 23021,\n",
       "         64075, 26385, 32284, 37401]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.phrase_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[203240, 206106, 202523, 200594, 209093, 189016, 167684, 176565, 197302,\n",
       "         164471, 157683, 163438, 212453, 213617, 168547, 181276, 205052, 159911,\n",
       "         198476, 205273, 215215, 158745, 208993, 218442, 182176, 221272, 219719,\n",
       "         185047, 171940, 214087, 184047, 197242, 202910, 174520, 210635, 202539,\n",
       "         214300, 170756, 186402, 181900, 215269, 191678, 214937, 212809, 173624,\n",
       "         214123, 162848, 178990, 179418, 173348, 160669, 183188, 209990, 221333,\n",
       "         207948, 193909, 159210, 188225, 199188, 179082, 220136, 182446, 188345,\n",
       "         193462]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.phrase_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId                               205705\n",
       "SentenceId                              10938\n",
       "Phrase                               and then\n",
       "Phrase_length                              38\n",
       "Tokenized_phrase    [xxbos, and, then, xxeos]\n",
       "Indexed_phrase                [2, 12, 320, 3]\n",
       "Name: 49644, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.iloc[49644]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 98\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings['then']\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, pretrained_embed_weights, embedding_dim, hidden_dim, context_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        assert pretrained_embed_weights.shape[1] == embedding_dim, \\\n",
    "                \"pretrained_embed_weights shape[1] does not match embedding_dim\"\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embed_weights, freeze=True)\n",
    "\n",
    "        self.rnn = nn.LSTM( embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional,\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        if bidirectional:\n",
    "            ## Word-level hierarchical attention:\n",
    "            self.ui = nn.Linear(2*hidden_dim, context_dim)\n",
    "            self.uw = nn.Parameter(torch.randn(context_dim))\n",
    "            \n",
    "            self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        else:\n",
    "            ## Word-level hierarchical attention:\n",
    "            self.ui = nn.Linear(hidden_dim, context_dim)\n",
    "            self.uw = nn.Parameter(torch.randn(context_d))\n",
    "            \n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent len, embedding_dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        #output = [batch size, senq len, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            ## Word-level hierarchical attention:\n",
    "            u_it = torch.tanh(self.ui(output)) # Batch size X senq len X context dim\n",
    "            weights = torch.softmax(u_it.matmul(self.uw), dim=1).unsqueeze(1)\n",
    "            \n",
    "            hidden = torch.sum(weights.matmul(output), dim=1) # Batch size X Hidden dim*2\n",
    "\n",
    "            hidden = self.dropout(hidden)\n",
    "        else:\n",
    "            u_it = torch.tanh(self.ui(output)) # Batch size X senq len X context dim\n",
    "            weights = torch.softmax(u_it.matmul(self.uw), dim=1).unsqueeze(1)\n",
    "            \n",
    "            hidden = torch.sum(weights.matmul(output), dim=1) # Batch size X Hidden dim\n",
    "\n",
    "            hidden = self.dropout(hidden)\n",
    "        \n",
    "        #if self.bidirectional:\n",
    "        #    hidden = [batch size, hid dim * num directions]\n",
    "        #else:\n",
    "        #    hidden = [batch size, hid dim]\n",
    "        \n",
    "        # with RELU\n",
    "        #return self.fc(self.relu(hidden))\n",
    "        \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameter and init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBED_WEIGHTS = torch.tensor(nlp.vocab.vectors.data, dtype=torch.float32)\n",
    "EMBEDDING_DIM = 308\n",
    "HIDDEN_DIM = 256\n",
    "CONTEXT_DIM = 70\n",
    "OUTPUT_DIM = 5\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "# Regularization hyperparameter\n",
    "DROPOUT = 0.5\n",
    "L2_LAMBDA = 0 #0.00001\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "N_EPOCHS = 100\n",
    "\n",
    "MODEL_SAVE_FILE = 'LSTM_with_attention_origin_embedding_in_model.pt'\n",
    "model = LSTMWithAttention(PRETRAINED_EMBED_WEIGHTS,\n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            CONTEXT_DIM,\n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the number of parameters in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,774,673 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, set_length):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        epoch_acc += (predictions.argmax(1) == batch.label).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / set_length, epoch_acc / set_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, set_length):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += (predictions.argmax(1) == batch.label).sum().item()\n",
    "        \n",
    "    return epoch_loss / set_length, epoch_acc / set_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define epoch time function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01437 | Train Acc: 61.95%\n",
      "\t Val. Loss: 0.01347 |  Val. Acc: 64.49%\n",
      "Epoch: 02 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01299 | Train Acc: 65.37%\n",
      "\t Val. Loss: 0.01265 |  Val. Acc: 66.24%\n",
      "Epoch: 03 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01226 | Train Acc: 67.16%\n",
      "\t Val. Loss: 0.01230 |  Val. Acc: 67.44%\n",
      "Epoch: 04 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01165 | Train Acc: 68.81%\n",
      "\t Val. Loss: 0.01204 |  Val. Acc: 67.66%\n",
      "Epoch: 05 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 0.01109 | Train Acc: 70.39%\n",
      "\t Val. Loss: 0.01176 |  Val. Acc: 68.81%\n",
      "Epoch: 06 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01065 | Train Acc: 71.62%\n",
      "\t Val. Loss: 0.01176 |  Val. Acc: 69.52%\n",
      "Epoch: 07 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01021 | Train Acc: 72.71%\n",
      "\t Val. Loss: 0.01163 |  Val. Acc: 69.34%\n",
      "Epoch: 08 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00985 | Train Acc: 73.62%\n",
      "\t Val. Loss: 0.01170 |  Val. Acc: 69.84%\n",
      "Epoch: 09 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00947 | Train Acc: 74.66%\n",
      "\t Val. Loss: 0.01168 |  Val. Acc: 69.67%\n",
      "Epoch: 10 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00911 | Train Acc: 75.54%\n",
      "\t Val. Loss: 0.01196 |  Val. Acc: 69.94%\n",
      "Epoch: 11 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00875 | Train Acc: 76.54%\n",
      "\t Val. Loss: 0.01271 |  Val. Acc: 68.54%\n",
      "Epoch: 12 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00838 | Train Acc: 77.43%\n",
      "\t Val. Loss: 0.01234 |  Val. Acc: 69.23%\n",
      "Epoch: 13 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00802 | Train Acc: 78.39%\n",
      "\t Val. Loss: 0.01287 |  Val. Acc: 68.85%\n",
      "Epoch: 14 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00760 | Train Acc: 79.54%\n",
      "\t Val. Loss: 0.01333 |  Val. Acc: 68.31%\n",
      "Epoch: 15 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00725 | Train Acc: 80.44%\n",
      "\t Val. Loss: 0.01383 |  Val. Acc: 68.24%\n",
      "Epoch: 16 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00686 | Train Acc: 81.45%\n",
      "\t Val. Loss: 0.01483 |  Val. Acc: 67.22%\n",
      "Epoch: 17 | Epoch Time: 0m 15s\n",
      "\tTrain Loss: 0.00643 | Train Acc: 82.62%\n",
      "\t Val. Loss: 0.01581 |  Val. Acc: 67.60%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-15332ba96c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-6b206d8692c3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, set_length)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# best_valid_loss = float('inf')\n",
    "best_valid_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "# For splotting\n",
    "all_train_losses = []\n",
    "all_valid_losses = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, len(train_data))\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, len(valid_data))\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "    if valid_acc > best_valid_acc:\n",
    "#         best_valid_loss = valid_loss\n",
    "        best_valid_acc = valid_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), saved_models_path + MODEL_SAVE_FILE)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    all_train_losses.append(train_loss)\n",
    "    all_valid_losses.append(valid_loss)\n",
    "    \n",
    "print(f'Best epoch: {best_epoch+1:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "# plt.xticks(range(0, 10))\n",
    "plt.plot(all_train_losses)\n",
    "plt.plot(all_valid_losses)\n",
    "plt.axvline(x=best_epoch, color='green')\n",
    "\n",
    "plt.legend(['train loss', 'valid loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 10\n"
     ]
    }
   ],
   "source": [
    "print(f'Best epoch: {best_epoch+1:02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.01213 | Test Acc: 69.18%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, len(test_data))\n",
    "\n",
    "print(f'Test Loss: {test_loss:.5f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reevaluate on valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.01196 | Test Acc: 69.94%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE))\n",
    "\n",
    "valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, len(valid_data))\n",
    "\n",
    "print(f'Test Loss: {valid_loss:.5f} | Test Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Kaggle Dataset and create submittion file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the model target file\n",
    "MODEL_SAVE_FILE_TARGET = 'LSTM_with_attention_origin_embedding_in_model-train-72.86-valid-69.84.pt'\n",
    "\n",
    "def predict_kaggle_test(model, iterator):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths)\n",
    "            \n",
    "            predictions = predictions.argmax(1)\n",
    "            \n",
    "            for i in range(len(batch)):\n",
    "                result.append([batch.id[0][i].item(), [batch.phrase_id[0][i].item(), predictions[i].item()]] )\n",
    "    \n",
    "    result.sort(key = lambda val: val[0])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, [156061, 2]],\n",
       " [1, [156062, 2]],\n",
       " [2, [156063, 2]],\n",
       " [3, [156064, 2]],\n",
       " [4, [156065, 2]],\n",
       " [5, [156066, 2]],\n",
       " [6, [156067, 3]],\n",
       " [7, [156068, 2]],\n",
       " [8, [156069, 3]],\n",
       " [9, [156070, 2]]]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE_TARGET))\n",
    "\n",
    "kaggle_result_list = predict_kaggle_test(model, kaggle_test_iterator)\n",
    "\n",
    "kaggle_result_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[66282, [222343, 2]],\n",
       " [66283, [222344, 2]],\n",
       " [66284, [222345, 2]],\n",
       " [66285, [222346, 2]],\n",
       " [66286, [222347, 2]],\n",
       " [66287, [222348, 0]],\n",
       " [66288, [222349, 1]],\n",
       " [66289, [222350, 1]],\n",
       " [66290, [222351, 1]],\n",
       " [66291, [222352, 1]]]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_result_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kaggle_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, xxmaj, an, xxeos]</td>\n",
       "      <td>[2, 7, 26, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156066</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but</td>\n",
       "      <td>68</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, xxeos]</td>\n",
       "      <td>[2, 2606, 1723, 30, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156067</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing</td>\n",
       "      <td>2</td>\n",
       "      <td>[xxbos, intermittently, pleasing, xxeos]</td>\n",
       "      <td>[2, 2606, 1723, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156068</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently</td>\n",
       "      <td>65</td>\n",
       "      <td>[xxbos, intermittently, xxeos]</td>\n",
       "      <td>[2, 2606, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156069</td>\n",
       "      <td>8545</td>\n",
       "      <td>pleasing</td>\n",
       "      <td>9</td>\n",
       "      <td>[xxbos, pleasing, xxeos]</td>\n",
       "      <td>[2, 1723, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>8545</td>\n",
       "      <td>but</td>\n",
       "      <td>55</td>\n",
       "      <td>[xxbos, but, xxeos]</td>\n",
       "      <td>[2, 30, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "5    156066        8545                        intermittently pleasing but   \n",
       "6    156067        8545                            intermittently pleasing   \n",
       "7    156068        8545                                     intermittently   \n",
       "8    156069        8545                                           pleasing   \n",
       "9    156070        8545                                                but   \n",
       "\n",
       "   Phrase_length                                   Tokenized_phrase  \\\n",
       "0            188  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "1             77  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "2              8                          [xxbos, xxmaj, an, xxeos]   \n",
       "3              1  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "4              6  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "5             68      [xxbos, intermittently, pleasing, but, xxeos]   \n",
       "6              2           [xxbos, intermittently, pleasing, xxeos]   \n",
       "7             65                     [xxbos, intermittently, xxeos]   \n",
       "8              9                           [xxbos, pleasing, xxeos]   \n",
       "9             55                                [xxbos, but, xxeos]   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]  \n",
       "1      [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "2                                      [2, 7, 26, 3]  \n",
       "3             [2, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "4                  [2, 2606, 1723, 30, 632, 1041, 3]  \n",
       "5                             [2, 2606, 1723, 30, 3]  \n",
       "6                                 [2, 2606, 1723, 3]  \n",
       "7                                       [2, 2606, 3]  \n",
       "8                                       [2, 1723, 3]  \n",
       "9                                         [2, 30, 3]  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_EXTENSION = '.submit.csv'\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(saved_models_path + MODEL_SAVE_FILE_TARGET + CSV_EXTENSION, mode='w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    csv_writer.writerow(['PhraseId', 'Sentiment'])\n",
    "    \n",
    "    for i in range(len(kaggle_result_list)):\n",
    "        csv_writer.writerow(kaggle_result_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
