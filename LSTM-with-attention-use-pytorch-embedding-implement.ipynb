{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load config and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import spacy, pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import random\n",
    "import inspect\n",
    "\n",
    "# Custom impport\n",
    "from common.common_classes import TensorField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.tsv', 'GRU-with-attention-implement.ipynb', 'LSTM-with-attention-implement.ipynb', 'prepare-word-embedding-nlp.ipynb', 'LSTM-with-attention-use-pytorch-embedding-implement.ipynb', 'tokenization.ipynb', 'test-batching-padding.ipynb', 'train.tsv', 'test-batching-padding-ok.ipynb', 'LSTM-implement.ipynb', 'sampleSubmission.csv', 'save_data', '.ipynb_checkpoints', '__init__.py', 'README.md', 'generate-result-for-report.ipynb', '.gitignore', '.git', 'common', 'simple-GRU-implement.ipynb']\n"
     ]
    }
   ],
   "source": [
    "path = \"./\"\n",
    "save_data_path = path + 'save_data/'\n",
    "large_save_data_path = '/notebooks/large-storage/'\n",
    "saved_models_path = '/notebooks/large-storage/saved-models/'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pickle.load(open(save_data_path + 'pre-processed-data.pkl', 'rb'))\n",
    "loaded_kaggle_test = pickle.load(open(save_data_path + 'pre-processed-kaggle-test.pkl', 'rb'))\n",
    "loaded_vocab = pickle.load(open(save_data_path + 'genereated-vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, a, series, of, escapades, demonstratin...</td>\n",
       "      <td>[2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, a, series, of, escapades, demonstratin...</td>\n",
       "      <td>[2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, a, series, xxeos]</td>\n",
       "      <td>[2, 10, 341, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, a, xxeos]</td>\n",
       "      <td>[2, 10, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, series, xxeos]</td>\n",
       "      <td>[2, 341, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Phrase_length  \\\n",
       "0          1            188   \n",
       "1          2             77   \n",
       "2          2              8   \n",
       "3          2              1   \n",
       "4          2              6   \n",
       "\n",
       "                                    Tokenized_phrase  \\\n",
       "0  [xxbos, a, series, of, escapades, demonstratin...   \n",
       "1  [xxbos, a, series, of, escapades, demonstratin...   \n",
       "2                          [xxbos, a, series, xxeos]   \n",
       "3                                  [xxbos, a, xxeos]   \n",
       "4                             [xxbos, series, xxeos]   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...  \n",
       "1  [2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...  \n",
       "2                                    [2, 10, 341, 3]  \n",
       "3                                         [2, 10, 3]  \n",
       "4                                        [2, 341, 3]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, xxmaj, an, xxeos]</td>\n",
       "      <td>[2, 7, 26, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "\n",
       "   Phrase_length                                   Tokenized_phrase  \\\n",
       "0            188  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "1             77  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "2              8                          [xxbos, xxmaj, an, xxeos]   \n",
       "3              1  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "4              6  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]  \n",
       "1      [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "2                                      [2, 7, 26, 3]  \n",
       "3             [2, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "4                  [2, 2606, 1723, 30, 632, 1041, 3]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n",
    "\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]\n",
    "\n",
    "MAX_LABEL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check max length of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "43802\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_index = -1\n",
    "for i in range(len(loaded_data['Tokenized_phrase'])):\n",
    "    if len(loaded_data['Tokenized_phrase'][i]) > max_len:\n",
    "        max_len = len(loaded_data['Tokenized_phrase'][i])\n",
    "        max_index = i\n",
    "        \n",
    "print(max_len)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "35146\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_index = -1\n",
    "for i in range(len(loaded_kaggle_test['Tokenized_phrase'])):\n",
    "    if len(loaded_kaggle_test['Tokenized_phrase'][i]) > max_len:\n",
    "        max_len = len(loaded_kaggle_test['Tokenized_phrase'][i])\n",
    "        max_index = i\n",
    "        \n",
    "print(max_len)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Encoding and prepraing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(large_save_data_path + 'process-spacy-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0.,\n",
       "       0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[BOS].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp.vocab.get_vector('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890280, 308)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test assigning pytorch embedding with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "embed_weights = torch.tensor(nlp.vocab.vectors.data, dtype=torch.float32)\n",
    "embed_layer = nn.Embedding.from_pretrained(embed_weights, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5439657043933447811\n",
      "row: 1081\n"
     ]
    }
   ],
   "source": [
    "cat_id = nlp.vocab.strings[u'cat']\n",
    "print(f\"ID: {cat_id}\")\n",
    "cat_row = nlp.vocab.vectors.key2row[cat_id]\n",
    "print(f\"row: {cat_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector: [-0.15067   -0.024468  -0.23368   -0.23378   -0.18382    0.32711\n",
      " -0.22084   -0.28777    0.12759    1.1656    -0.64163   -0.098455\n",
      " -0.62397    0.010431  -0.25653    0.31799    0.037779   1.1904\n",
      " -0.17714   -0.2595    -0.31461    0.038825  -0.15713   -0.13484\n",
      "  0.36936   -0.30562   -0.40619   -0.38965    0.3686     0.013963\n",
      " -0.6895     0.004066  -0.1367     0.32564    0.24688   -0.14011\n",
      "  0.53889   -0.80441   -0.1777    -0.12922    0.16303    0.14917\n",
      " -0.068429  -0.33922    0.18495   -0.082544  -0.46892    0.39581\n",
      " -0.13742   -0.35132    0.22223   -0.144     -0.048287   0.3379\n",
      " -0.31916    0.20526    0.098624  -0.23877    0.045338   0.43941\n",
      "  0.030385  -0.013821  -0.093273  -0.18178    0.19438   -0.3782\n",
      "  0.70144    0.16236    0.0059111  0.024898  -0.13613   -0.11425\n",
      " -0.31598   -0.14209    0.028194   0.5419    -0.42413   -0.599\n",
      "  0.24976   -0.27003    0.14964    0.29287   -0.31281    0.16543\n",
      " -0.21045   -0.4408     1.2174     0.51236    0.56209    0.14131\n",
      "  0.092514   0.71396   -0.021051  -0.33704   -0.20275   -0.36181\n",
      "  0.22055   -0.25665    0.28425   -0.16968    0.058029   0.61182\n",
      "  0.31576   -0.079185   0.35538   -0.51236    0.4235    -0.30033\n",
      " -0.22376    0.15223   -0.048292   0.23532    0.46507   -0.67579\n",
      " -0.32905    0.08446   -0.22123   -0.045333   0.34463   -0.1455\n",
      " -0.18047   -0.17887    0.96879   -1.0028    -0.47343    0.28542\n",
      "  0.56382   -0.33211   -0.38275   -0.2749    -0.22955   -0.24265\n",
      " -0.37689    0.24822    0.36941    0.14651   -0.37864    0.31134\n",
      " -0.28449    0.36948   -2.8174    -0.38319   -0.022373   0.56376\n",
      "  0.40131   -0.42131   -0.11311   -0.17317    0.1411    -0.13194\n",
      "  0.18494    0.097692  -0.097341  -0.23987    0.16631   -0.28556\n",
      "  0.0038654  0.53292   -0.32367   -0.38744    0.27011   -0.34181\n",
      " -0.27702   -0.67279   -0.10771   -0.062189  -0.24783   -0.070884\n",
      " -0.20898    0.062404   0.022372   0.13408    0.1305    -0.19546\n",
      " -0.46849    0.77731   -0.043978   0.3827    -0.23376    1.0457\n",
      " -0.14371   -0.3565    -0.080713  -0.31047   -0.57822   -0.28067\n",
      " -0.069678   0.068929  -0.16227   -0.63934   -0.62149    0.11222\n",
      " -0.16969   -0.54637    0.49661    0.46565    0.088294  -0.48496\n",
      "  0.69263   -0.068977  -0.53709    0.20802   -0.42987   -0.11921\n",
      "  0.1174    -0.18443    0.43797   -0.1236     0.3607    -0.19608\n",
      " -0.35366    0.18808   -0.5061     0.14455   -0.024368  -0.10772\n",
      " -0.0115     0.58634   -0.054461   0.0076487 -0.056297   0.27193\n",
      "  0.23096   -0.29296   -0.24325    0.10317   -0.10014    0.7089\n",
      "  0.17402   -0.0037509 -0.46304    0.11806   -0.16457   -0.38609\n",
      "  0.14524    0.098122  -0.12352   -0.1047     0.39047   -0.3063\n",
      " -0.65375   -0.0044248 -0.033876   0.037114  -0.27472    0.0053147\n",
      "  0.30737    0.12528   -0.19527   -0.16461    0.087518  -0.051107\n",
      " -0.16323    0.521      0.10822   -0.060379  -0.71735   -0.064327\n",
      "  0.37043   -0.41054   -0.2728    -0.30217    0.015771  -0.43056\n",
      "  0.35647    0.17188   -0.54598   -0.21541   -0.044889  -0.10597\n",
      " -0.54391    0.53908    0.070938   0.097839   0.097908   0.17805\n",
      "  0.18995    0.49962   -0.18529    0.051234   0.019574   0.24805\n",
      "  0.3144    -0.29304    0.54235    0.46672    0.26017   -0.44705\n",
      "  0.28287   -0.033345  -0.33181   -0.10902   -0.023324   0.2106\n",
      " -0.29633    0.81506    0.038524   0.46004    0.17187   -0.29804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.       ]\n",
      "embedding: tensor([[-0.1507, -0.0245, -0.2337, -0.2338, -0.1838,  0.3271, -0.2208, -0.2878,\n",
      "          0.1276,  1.1656, -0.6416, -0.0985, -0.6240,  0.0104, -0.2565,  0.3180,\n",
      "          0.0378,  1.1904, -0.1771, -0.2595, -0.3146,  0.0388, -0.1571, -0.1348,\n",
      "          0.3694, -0.3056, -0.4062, -0.3896,  0.3686,  0.0140, -0.6895,  0.0041,\n",
      "         -0.1367,  0.3256,  0.2469, -0.1401,  0.5389, -0.8044, -0.1777, -0.1292,\n",
      "          0.1630,  0.1492, -0.0684, -0.3392,  0.1849, -0.0825, -0.4689,  0.3958,\n",
      "         -0.1374, -0.3513,  0.2222, -0.1440, -0.0483,  0.3379, -0.3192,  0.2053,\n",
      "          0.0986, -0.2388,  0.0453,  0.4394,  0.0304, -0.0138, -0.0933, -0.1818,\n",
      "          0.1944, -0.3782,  0.7014,  0.1624,  0.0059,  0.0249, -0.1361, -0.1142,\n",
      "         -0.3160, -0.1421,  0.0282,  0.5419, -0.4241, -0.5990,  0.2498, -0.2700,\n",
      "          0.1496,  0.2929, -0.3128,  0.1654, -0.2104, -0.4408,  1.2174,  0.5124,\n",
      "          0.5621,  0.1413,  0.0925,  0.7140, -0.0211, -0.3370, -0.2027, -0.3618,\n",
      "          0.2206, -0.2567,  0.2842, -0.1697,  0.0580,  0.6118,  0.3158, -0.0792,\n",
      "          0.3554, -0.5124,  0.4235, -0.3003, -0.2238,  0.1522, -0.0483,  0.2353,\n",
      "          0.4651, -0.6758, -0.3291,  0.0845, -0.2212, -0.0453,  0.3446, -0.1455,\n",
      "         -0.1805, -0.1789,  0.9688, -1.0028, -0.4734,  0.2854,  0.5638, -0.3321,\n",
      "         -0.3828, -0.2749, -0.2296, -0.2427, -0.3769,  0.2482,  0.3694,  0.1465,\n",
      "         -0.3786,  0.3113, -0.2845,  0.3695, -2.8174, -0.3832, -0.0224,  0.5638,\n",
      "          0.4013, -0.4213, -0.1131, -0.1732,  0.1411, -0.1319,  0.1849,  0.0977,\n",
      "         -0.0973, -0.2399,  0.1663, -0.2856,  0.0039,  0.5329, -0.3237, -0.3874,\n",
      "          0.2701, -0.3418, -0.2770, -0.6728, -0.1077, -0.0622, -0.2478, -0.0709,\n",
      "         -0.2090,  0.0624,  0.0224,  0.1341,  0.1305, -0.1955, -0.4685,  0.7773,\n",
      "         -0.0440,  0.3827, -0.2338,  1.0457, -0.1437, -0.3565, -0.0807, -0.3105,\n",
      "         -0.5782, -0.2807, -0.0697,  0.0689, -0.1623, -0.6393, -0.6215,  0.1122,\n",
      "         -0.1697, -0.5464,  0.4966,  0.4656,  0.0883, -0.4850,  0.6926, -0.0690,\n",
      "         -0.5371,  0.2080, -0.4299, -0.1192,  0.1174, -0.1844,  0.4380, -0.1236,\n",
      "          0.3607, -0.1961, -0.3537,  0.1881, -0.5061,  0.1445, -0.0244, -0.1077,\n",
      "         -0.0115,  0.5863, -0.0545,  0.0076, -0.0563,  0.2719,  0.2310, -0.2930,\n",
      "         -0.2432,  0.1032, -0.1001,  0.7089,  0.1740, -0.0038, -0.4630,  0.1181,\n",
      "         -0.1646, -0.3861,  0.1452,  0.0981, -0.1235, -0.1047,  0.3905, -0.3063,\n",
      "         -0.6538, -0.0044, -0.0339,  0.0371, -0.2747,  0.0053,  0.3074,  0.1253,\n",
      "         -0.1953, -0.1646,  0.0875, -0.0511, -0.1632,  0.5210,  0.1082, -0.0604,\n",
      "         -0.7174, -0.0643,  0.3704, -0.4105, -0.2728, -0.3022,  0.0158, -0.4306,\n",
      "          0.3565,  0.1719, -0.5460, -0.2154, -0.0449, -0.1060, -0.5439,  0.5391,\n",
      "          0.0709,  0.0978,  0.0979,  0.1780,  0.1900,  0.4996, -0.1853,  0.0512,\n",
      "          0.0196,  0.2481,  0.3144, -0.2930,  0.5423,  0.4667,  0.2602, -0.4471,\n",
      "          0.2829, -0.0333, -0.3318, -0.1090, -0.0233,  0.2106, -0.2963,  0.8151,\n",
      "          0.0385,  0.4600,  0.1719, -0.2980,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# cat_embedding is a Tensor representation of cat_vector\n",
    "cat_vector = nlp.vocab.vectors[cat_id]\n",
    "print(f\"vector: {cat_vector}\")\n",
    "cat_embedding = embed_layer(torch.LongTensor([cat_row]))\n",
    "print(f\"embedding: {cat_embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_embedding.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([890280, 308])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer.weight.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15321870174910142188\n",
      "row: 684831\n"
     ]
    }
   ],
   "source": [
    "pad_id = nlp.vocab.strings[PAD]\n",
    "print(f\"ID: {pad_id}\")\n",
    "pad_row = nlp.vocab.vectors.key2row[pad_id]\n",
    "print(f\"row: {pad_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle Train dataset\n",
    "PHRASE_ID = data.Field(use_vocab = False)\n",
    "TEXT = TensorField(include_lengths = True, use_vocab = False, sequential = False, pad_token = pad_row)\n",
    "LABEL = data.LabelField(use_vocab = False, dtype=torch.long)\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "ID_TEST = data.Field(use_vocab = False)\n",
    "PHRASE_ID_TEST = data.Field(use_vocab = False)\n",
    "TEXT_TEST = TensorField(include_lengths = True, use_vocab = False, sequential = False, pad_token = pad_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle Train dataset\n",
    "fields = [('id', PHRASE_ID), ('text', TEXT), ('label', LABEL)]\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "fields_test = [('id', ID_TEST), ('phrase_id', PHRASE_ID_TEST), ('text', TEXT_TEST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_data['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_kaggle_test['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_rown: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7fd094c43e48>,\n",
       " <torchtext.data.example.Example at 0x7fd094c43eb8>,\n",
       " <torchtext.data.example.Example at 0x7fd094c43ef0>,\n",
       " <torchtext.data.example.Example at 0x7fd094c43f28>,\n",
       " <torchtext.data.example.Example at 0x7fd094c43f60>,\n",
       " <torchtext.data.example.Example at 0x7fd094c43f98>,\n",
       " <torchtext.data.example.Example at 0x7fd094c43fd0>,\n",
       " <torchtext.data.example.Example at 0x7fd094c44048>,\n",
       " <torchtext.data.example.Example at 0x7fd094c44080>,\n",
       " <torchtext.data.example.Example at 0x7fd0ae92ec50>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unknown row\n",
    "unknown_id = nlp.vocab.strings[UNK]\n",
    "unknown_row = nlp.vocab.vectors.key2row[unknown_id]\n",
    "print(f\"unknown_rown: {unknown_row}\")\n",
    "\n",
    "# For Kaggle Train dataset\n",
    "examples = []\n",
    "length = len(loaded_data['Phrase'])\n",
    "for i in range(length):\n",
    "    indexes = []\n",
    "    for j in range(len(loaded_data['Tokenized_phrase'][i])):\n",
    "        if nlp.vocab.has_vector(loaded_data['Tokenized_phrase'][i][j]):\n",
    "            token_id = nlp.vocab.strings[loaded_data['Tokenized_phrase'][i][j]]\n",
    "            token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "\n",
    "            indexes.append(token_row)\n",
    "        else:\n",
    "            indexes.append(unknown_row)\n",
    "    \n",
    "    examples.append(data.Example.fromlist([ [loaded_data['PhraseId'][i]], indexes, loaded_data['Sentiment'][i]], fields))\n",
    "    \n",
    "examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_rown: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7fd00033bb70>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bba8>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bc18>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bc50>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bc88>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bcc0>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bcf8>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bd30>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bd68>,\n",
       " <torchtext.data.example.Example at 0x7fd00033bda0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unknown row\n",
    "unknown_id = nlp.vocab.strings[UNK]\n",
    "unknown_row = nlp.vocab.vectors.key2row[unknown_id]\n",
    "print(f\"unknown_rown: {unknown_row}\")\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "examples_test = []\n",
    "length = len(loaded_kaggle_test['Phrase'])\n",
    "for i in range(length):\n",
    "    indexes = []\n",
    "    for j in range(len(loaded_kaggle_test['Tokenized_phrase'][i])):\n",
    "        if nlp.vocab.has_vector(loaded_kaggle_test['Tokenized_phrase'][i][j]):\n",
    "            token_id = nlp.vocab.strings[loaded_kaggle_test['Tokenized_phrase'][i][j]]\n",
    "            token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "            \n",
    "            indexes.append(token_row)\n",
    "        else:\n",
    "            indexes.append(unknown_row)\n",
    "    \n",
    "    examples_test.append(data.Example.fromlist([ [i], [loaded_kaggle_test['PhraseId'][i]], indexes ], fields_test))\n",
    "    \n",
    "examples_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[684832, 6, 684833]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 684833\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings[EOS]\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[684832, 40929, 11176, 29, 737, 3812, 1240, 684833]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_test[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 737\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings['mostly']\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[3].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data.Dataset(examples, fields)\n",
    "data_set_test = data.Dataset(examples_test, fields_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.sort_key = lambda x: len(x.text)\n",
    "data_set_test.sort_key = lambda x: len(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 9131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data_set.split([0.8, 0.1, 0.1], random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sort_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124848"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_set.sort_key = lambda x: len(x.text)\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsource(train_data.sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_set_test.sort_key = lambda x: len(x.text)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsource(data_set_test.sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)\n",
    "\n",
    "kaggle_test_iterator = data.BucketIterator(\n",
    "    data_set_test, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_iterator = iter(train_iterator)\n",
    "batch = next(raw_train_iterator)\n",
    "\n",
    "raw_kaggle_test_iterator = iter(kaggle_test_iterator)\n",
    "batch_test = next(raw_kaggle_test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = batch.text\n",
    "\n",
    "c, d = batch_test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 9])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[684832,    200,     63,     90,      6, 333750,      8,  87261, 684833],\n",
       "        [684832,      6,    176,     42,    313,   2358,   4023,   1214, 684833],\n",
       "        [684832,      3,    141,    253,      6,   1889,    498,      2, 684833],\n",
       "        [684832,    205,     56,     45,    181,   2593,   5716,  10983, 684833],\n",
       "        [684832,    622,    891,     13,      3,     99,      2,   1864, 684833],\n",
       "        [684832,     40,      2,    631,    354,      2,  16439,    810, 684833],\n",
       "        [684832,      5,     23,      6, 684837,    186, 684837,  78888, 684833],\n",
       "        [684832,    308,    407,   2325,      3,   2105,      8,   3242, 684833],\n",
       "        [684832,   3868,    362,    495,    169,      3,    226,  33789, 684833],\n",
       "        [684832,   4407,     13,     58,  12745,    239,      8,  12965, 684833],\n",
       "        [684832,  12657,     13,     36,     94,   2996,     36,  60409, 684833],\n",
       "        [684832,     13,   1321,    495,     29,    371,      3,   2181, 684833],\n",
       "        [684832,     11,      2,      5,     75,   1274,     42,    247, 684833],\n",
       "        [684832,     13,      6,   1843,    641,    506,      8,     81, 684833],\n",
       "        [684832,    282,     57,    380,      2,     29,     39,   4727, 684833],\n",
       "        [684832,      6,  11738,      8,    528,     45,  20602,     10, 684833],\n",
       "        [684832,     76,      6,   1695,      2,  87239,    173,      1, 684833],\n",
       "        [684832,    108,     43,      3,  24748,   2957,   1592,    641, 684833],\n",
       "        [684832,    124,    201,     28,    100,     16,      6,    195, 684833],\n",
       "        [684832,  27607,      2, 640808,    569,      7,   4809,   9103, 684833],\n",
       "        [684832,     79,   1270, 684837,  29162, 684837,  29034,   1198, 684833],\n",
       "        [684832,     24,      6, 684837, 660487, 684837,  73780,   1910, 684833],\n",
       "        [684832,      3,    202,    864,     33,    309,     33,  24733, 684833],\n",
       "        [684832,      3,   3233,     42,     93,    227,   2215,    675, 684833],\n",
       "        [684832,     43,     10,     88,     15,    125,    249,    229, 684833],\n",
       "        [684832,      0, 684837,  30655,      7, 684837, 467330,      0, 684833],\n",
       "        [684832,      3,   2175,  13465, 519081,      8, 684837,  15900, 684833],\n",
       "        [684832,     14,   3535,    216,      7,    412,      6,    176, 684833],\n",
       "        [684832,      6,  22996,      2,   2678,     33,    929,    682, 684833],\n",
       "        [684832, 684837,  21149, 684837,  37420,      7,  11662,   3744, 684833],\n",
       "        [684832,     70,    133, 684837,  18291,    208,      5,    229, 684833],\n",
       "        [684832,     76,     28,  11341,      6,    469,     91,   1198, 684833],\n",
       "        [684832,  44940,     75,  28321,   2467,     33,  18160,   2996, 684833],\n",
       "        [684832,      3,  14074, 294749,      8,      3,   2181,   1905, 684833],\n",
       "        [684832,     23,  13370,     60,     13, 684837,  14378,      7, 684833],\n",
       "        [684832, 684837,      7,  21271,     12,    672,   7635,    772, 684833],\n",
       "        [684832,    214,      3,  30324,      8,  86385,      7,  19761, 684833],\n",
       "        [684832,    111,    510,    472,      5,     19,    293,     10, 684833],\n",
       "        [684832, 684837,     37, 684837,      3, 684837,  82364,   1107, 684833],\n",
       "        [684832, 555441,     68,    245,     31,    498,     54,    239, 684833],\n",
       "        [684832,   3289,      5,      3,   1406,     33,   5960,   2274, 684833],\n",
       "        [684832,    238,  11506,    171,    290,     33,   3693,   3289, 684833],\n",
       "        [684832,  53225,     33,    264, 684837,   6391, 684837, 292733, 684833],\n",
       "        [684832,  99259,    136,    121,      3,    915,    111,   7968, 684833],\n",
       "        [684832,      5, 111434,     12,  10228,     24,   1277, 312845, 684833],\n",
       "        [684832,      6,    649,      2,    354,  46898,    898,      1, 684833],\n",
       "        [684832,     12,     14,   2467,  17537,   1681,     42,    202, 684833],\n",
       "        [684832, 684837, 145780,      7, 684837, 174587, 684837, 139289, 684833],\n",
       "        [684832,      5,      3,  51783,    610,     14,  12530,      7, 684833],\n",
       "        [684832, 684837,  21232,    498,   1235,     56,     45,    569, 684833],\n",
       "        [684832,    244,     62,     14,   3477,     16,   1438,      7, 684833],\n",
       "        [684832,      5,    103,      6,    498,     24,    171,   1065, 684833],\n",
       "        [684832,     23,     13,    379,   2158,     80, 684837,   7124, 684833],\n",
       "        [684832, 684837,    334,   2861,    293,    214,   2446,   2639, 684833],\n",
       "        [684832,      3,    346,      8, 684837,   2084, 684837,   2954, 684833],\n",
       "        [684832,   1865,      5,      3,   8866,   4861,   3724,      1, 684833],\n",
       "        [684832,    141,     91,     33,  12351,    354,  29906,   3974, 684833],\n",
       "        [684832,     14,   3908,      5, 684837,   3561, 684837,  11662, 684833],\n",
       "        [684832,     26,      6,   1202,      7,  43402,    449,     74, 684833],\n",
       "        [684832,   7357,      7,    141,  21340,    498,     13,    178, 684833],\n",
       "        [684832,     16, 684837,   1136, 684837, 140557,     14,   1505, 684833],\n",
       "        [684832,     12,     46,     23,    342,     13, 684837,  59542, 684833],\n",
       "        [684832,     14,     28,    112,     94,      8,    194,      1, 684833],\n",
       "        [684832,     11,    157,      5,    541,   5238,    111,   6234, 684833]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 0, 2, 2, 1, 3, 3, 1, 3, 3, 2, 2, 2, 2, 2, 0, 2, 1, 4, 3, 2, 3, 2,\n",
       "        2, 2, 1, 3, 1, 2, 2, 1, 3, 1, 2, 2, 1, 4, 2, 3, 2, 3, 2, 2, 1, 4, 2, 2,\n",
       "        2, 3, 2, 3, 1, 2, 2, 3, 4, 2, 2, 4, 2, 2, 1, 4], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[133918,  57783,  94049,  86671,  84086,  74128, 112683, 126943,  12599,\n",
       "         138419,  47937,  62635, 104584,  86587, 113162,  81036,  62472, 147974,\n",
       "          32209, 133654,  95241, 137072,  66415,  75555,  53039, 130485,  79837,\n",
       "         152257,  39951, 136680, 121126, 102615, 101662, 119728, 108929, 145776,\n",
       "          36689,  66928, 109732, 109843, 130506,  33026, 123268, 155495, 114095,\n",
       "          27453, 122599,  82520,  21535, 104973,  91096,  97182,  84542, 119081,\n",
       "         104435,  65401,  30863, 141808,  39997, 145932,  46149, 125167, 132902,\n",
       "         117864]], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['Sentiment'][117864-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[684832,    858,     37,     10,     14,    117,      5,     23,    191,\n",
       "         684833],\n",
       "        [684832, 684837,     16, 684837, 146405, 684837,  11721,     92,      1,\n",
       "         684833],\n",
       "        [684832,     19,     16,      3,    420,  20523,      8,     85,    711,\n",
       "         684833],\n",
       "        [684832, 130283,      9,     78,    418,    154,     10,     14,   4905,\n",
       "         684833],\n",
       "        [684832, 684837,   4628,     76,      6,    127,      5, 298172,      2,\n",
       "         684833],\n",
       "        [684832,     36,    194,     63,     90,  12832,     13,      6,  24748,\n",
       "         684833],\n",
       "        [684832,   4089,   5529,      7,    588,     33,  34423,   4043,   2809,\n",
       "         684833],\n",
       "        [684832,    171,    227,  43211,      2,  97814,     33,  98296,  15611,\n",
       "         684833],\n",
       "        [684832,      8, 684837,   7078,    213,  36288,     24,    334,     99,\n",
       "         684833],\n",
       "        [684832,  38669,  13120,      8,     51,   8953,     33,   2467,  58039,\n",
       "         684833],\n",
       "        [684832,      6,  49071,   2076,  13327,      7,   2642,    898,      2,\n",
       "         684833],\n",
       "        [684832,  42793,   7635,    772,  43571,   7635,    772,  21192,  15966,\n",
       "         684833],\n",
       "        [684832,  35010,     13,      3,   3770,      8,  33096, 684837,  19642,\n",
       "         684833],\n",
       "        [684832,    216,    983,      5,    100,     10,   1257,     36,   7540,\n",
       "         684833],\n",
       "        [684832, 684837,    254,     39,   1493,   3592,   7049,  38826,  61157,\n",
       "         684833],\n",
       "        [684832,     42,      3,   5915,  75364,      7,  33060,  22935,   1931,\n",
       "         684833],\n",
       "        [684832, 684837,      3, 684837,      0,  15319,  29798,      2,     29,\n",
       "         684833],\n",
       "        [684832, 684837,  20842,     64, 684837, 150812,   2289, 684837,  23085,\n",
       "         684833],\n",
       "        [684832,      2,  44484,      2, 106919,      2,      7,    557,    789,\n",
       "         684833],\n",
       "        [684832,      3,   4337,   1564,   5279, 684837,  84870, 684837,      0,\n",
       "         684833],\n",
       "        [684832,     63,   1195,     90,    106,   2325,   1120,    111,    309,\n",
       "         684833],\n",
       "        [684832,     23,    407, 684837,   2441, 684837,   4623, 684837,  14615,\n",
       "         684833],\n",
       "        [684832, 684837, 138017, 684837, 331965,     14,   1249,  23325,   1716,\n",
       "         684833],\n",
       "        [684832,    126,    132,     33,    187,      2,    569,      7,   3535,\n",
       "         684833],\n",
       "        [684832,     92,    248,     57,      3,   3883,      8,      6,  48980,\n",
       "         684833],\n",
       "        [684832,     35,     25,     15,    100,   4098,     37,     12,    749,\n",
       "         684833],\n",
       "        [684832,    275,    655,      3,    373,      8,      3,   2527, 106382,\n",
       "         684833],\n",
       "        [684832,     24,   1270,    645,  36343,      7,  14416,   2446,  20055,\n",
       "         684833],\n",
       "        [684832,     27,     38,    526,    216,      5,    100,      6,  23700,\n",
       "         684833],\n",
       "        [684832,      9,    111,  17343,   6345, 684837,      3, 684837,   1907,\n",
       "         684833],\n",
       "        [684832,     36,     70,    201,     23,    618,     13,  29399,  41423,\n",
       "         684833],\n",
       "        [684832, 684837,    305,      9,    997,     48,     10,     13,  21183,\n",
       "         684833],\n",
       "        [684832,     80,      3,    257,      8, 684837,  51012, 684837,   2571,\n",
       "         684833],\n",
       "        [684832, 684837,     59,    582,      5, 684837,  15335,   7311,     18,\n",
       "         684833],\n",
       "        [684832, 684837,    377, 684837,  21790,   6456,     13,  29153,  45137,\n",
       "         684833],\n",
       "        [684832,    100,     13,      3,   2486,      8,    208,     69,     91,\n",
       "         684833],\n",
       "        [684832,     65,     11,     15,      6,  17521,    751,    142,      1,\n",
       "         684833],\n",
       "        [684832, 581431,      3,   1198,     57,      3,    126,   1448,     74,\n",
       "         684833],\n",
       "        [684832,     23,      6,     91,    447,     33,    777,    112,    207,\n",
       "         684833],\n",
       "        [684832,      5,   3922,     57,     39,  10914,     72,    449,   2957,\n",
       "         684833],\n",
       "        [684832,    187,    280,      6,    775,   2747,     13,     93,   6291,\n",
       "         684833],\n",
       "        [684832,  20423,    500,    121,     54,   2072,     33,   2400,   3613,\n",
       "         684833],\n",
       "        [684832,   2357,  11236,    451,    111,    868,      5,      3,    910,\n",
       "         684833],\n",
       "        [684832, 684837,     10,  28157,      5,     23,      6,    200,    224,\n",
       "         684833],\n",
       "        [684832,      6,  13897,     13,      6,   5776,     24,    116,  14766,\n",
       "         684833],\n",
       "        [684832,    588,     33,  47452,   7142,  80686,  39375,     33,  39375,\n",
       "         684833],\n",
       "        [684832,     80,   7854,  24495,      3,    996,      8,    404,  43102,\n",
       "         684833],\n",
       "        [684832,      2,    112,   1669,      2,      7,   2845,   1334,      1,\n",
       "         684833],\n",
       "        [684832,     11,  19429,     36,    132,     36,    221,     33,  11053,\n",
       "         684833],\n",
       "        [684832,      6,   4171,      8,  18108, 153540,      7,   4132,  54142,\n",
       "         684833],\n",
       "        [684832,     24, 684837, 177229,     13,  12311,     14, 684837,    940,\n",
       "         684833],\n",
       "        [684832,      8, 684837,   3561,    905,     13,     58,  28836,    110,\n",
       "         684833],\n",
       "        [684832,    235,      3,    498,      6,  21062,      7,   4285,   5720,\n",
       "         684833],\n",
       "        [684832,      9,     71,    633,     31,   5465,     33,  11233,  23961,\n",
       "         684833],\n",
       "        [684832,   1163,   3862,     77,     10,     14,      6,  20276,   1197,\n",
       "         684833],\n",
       "        [684832, 684837,  37903, 684837,  27644,     76,      6,  84051,  19804,\n",
       "         684833],\n",
       "        [684832,      0,     14,    885,      5,   8041,   8630,      7,    356,\n",
       "         684833],\n",
       "        [684832,     26,  80910,   4861,      7,    377,      8,  95862,   2327,\n",
       "         684833],\n",
       "        [684832,      3,  78776,      8,      3,    770,     33,   5742,    610,\n",
       "         684833],\n",
       "        [684832, 684837,     10,     14,   2662, 173886,     51,      3,    110,\n",
       "         684833],\n",
       "        [684832, 684837,    195,      3,   1198,  79457,     42,    190,    373,\n",
       "         684833],\n",
       "        [684832,     12,     97,     79,    245,    688,     60,      3,    332,\n",
       "         684833],\n",
       "        [684832, 684837,      3,   1198,    235,      6,  10348,   1481,     64,\n",
       "         684833],\n",
       "        [684832,      9,     71,     28,    121,      3, 684837,   2687,   4499,\n",
       "         684833]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[47179, 50045, 46462, 44533, 53032, 32955, 11623, 20504, 41241,  8410,\n",
       "          1622,  7377, 56392, 57556, 12486, 25215, 48991,  3850, 42415, 49212,\n",
       "         59154,  2684, 52932, 62381, 26115, 65211, 63658, 28986, 15879, 58026,\n",
       "         27986, 41181, 46849, 18459, 54574, 46478, 58239, 14695, 30341, 25839,\n",
       "         59208, 35617, 58876, 56748, 17563, 58062,  6787, 22929, 23357, 17287,\n",
       "          4608, 27127, 53929, 65272, 51887, 37848,  3149, 32164, 43127, 23021,\n",
       "         64075, 26385, 32284, 37401]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.phrase_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[203240, 206106, 202523, 200594, 209093, 189016, 167684, 176565, 197302,\n",
       "         164471, 157683, 163438, 212453, 213617, 168547, 181276, 205052, 159911,\n",
       "         198476, 205273, 215215, 158745, 208993, 218442, 182176, 221272, 219719,\n",
       "         185047, 171940, 214087, 184047, 197242, 202910, 174520, 210635, 202539,\n",
       "         214300, 170756, 186402, 181900, 215269, 191678, 214937, 212809, 173624,\n",
       "         214123, 162848, 178990, 179418, 173348, 160669, 183188, 209990, 221333,\n",
       "         207948, 193909, 159210, 188225, 199188, 179082, 220136, 182446, 188345,\n",
       "         193462]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.phrase_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId                               205705\n",
       "SentenceId                              10938\n",
       "Phrase                               and then\n",
       "Phrase_length                              38\n",
       "Tokenized_phrase    [xxbos, and, then, xxeos]\n",
       "Indexed_phrase                [2, 12, 320, 3]\n",
       "Name: 49644, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.iloc[49644]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 98\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings['then']\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, pretrained_embed_weights, embedding_dim, hidden_dim, context_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, padding_idx=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        assert pretrained_embed_weights.shape[1] == embedding_dim, \\\n",
    "                \"pretrained_embed_weights shape[1] does not match embedding_dim\"\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embed_weights, freeze=True, padding_idx=padding_idx)\n",
    "\n",
    "        self.rnn = nn.LSTM( embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional,\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        if bidirectional:\n",
    "            ## Word-level hierarchical attention:\n",
    "            self.ui = nn.Linear(2*hidden_dim, context_dim)\n",
    "            self.uw = nn.Parameter(torch.randn(context_dim))\n",
    "            \n",
    "            self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        else:\n",
    "            ## Word-level hierarchical attention:\n",
    "            self.ui = nn.Linear(hidden_dim, context_dim)\n",
    "            self.uw = nn.Parameter(torch.randn(context_d))\n",
    "            \n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent len, embedding_dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        #output = [batch size, senq len, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            ## Word-level hierarchical attention:\n",
    "            u_it = torch.tanh(self.ui(output)) # Batch size X senq len X context dim\n",
    "            weights = torch.softmax(u_it.matmul(self.uw), dim=1).unsqueeze(1)\n",
    "            \n",
    "            hidden = torch.sum(weights.matmul(output), dim=1) # Batch size X Hidden dim*2\n",
    "\n",
    "            hidden = self.dropout(hidden)\n",
    "        else:\n",
    "            u_it = torch.tanh(self.ui(output)) # Batch size X senq len X context dim\n",
    "            weights = torch.softmax(u_it.matmul(self.uw), dim=1).unsqueeze(1)\n",
    "            \n",
    "            hidden = torch.sum(weights.matmul(output), dim=1) # Batch size X Hidden dim\n",
    "\n",
    "            hidden = self.dropout(hidden)\n",
    "        \n",
    "        #if self.bidirectional:\n",
    "        #    hidden = [batch size, hid dim * num directions]\n",
    "        #else:\n",
    "        #    hidden = [batch size, hid dim]\n",
    "        \n",
    "        # with RELU\n",
    "        #return self.fc(self.relu(hidden))\n",
    "        \n",
    "        return self.softmax(self.fc(hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameter and init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_rown: 684831\n"
     ]
    }
   ],
   "source": [
    "# Get padding index\n",
    "pad_id = nlp.vocab.strings[PAD]\n",
    "pad_row = nlp.vocab.vectors.key2row[pad_id]\n",
    "print(f\"pad_rown: {pad_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBED_WEIGHTS = torch.tensor(nlp.vocab.vectors.data, dtype=torch.float32)\n",
    "EMBEDDING_DIM = 308\n",
    "HIDDEN_DIM = 256\n",
    "CONTEXT_DIM = 70\n",
    "OUTPUT_DIM = 5\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "PADDING_IDX=None\n",
    "\n",
    "# Regularization hyperparameter\n",
    "DROPOUT = 0.6\n",
    "L2_LAMBDA = 0 #0.00001\n",
    "LABEL_SMOOTHING = 0.3\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "N_EPOCHS = 100\n",
    "\n",
    "MODEL_SAVE_FILE = 'LSTM_with_attention_embedding_in_model_origin.pt'\n",
    "model = LSTMWithAttention(PRETRAINED_EMBED_WEIGHTS,\n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            CONTEXT_DIM,\n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT,\n",
    "            PADDING_IDX).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the number of parameters in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,774,673 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.KLDivLoss(reduction='batchmean').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label smoothing function\n",
    "def smooth_one_hot(true_labels: torch.Tensor, classes: int, smoothing=0.0):\n",
    "    \"\"\"\n",
    "    if smoothing == 0, it's one-hot method\n",
    "    if 0 < smoothing < 1, it's smooth method\n",
    "\n",
    "    \"\"\"\n",
    "    assert 0 <= smoothing < 1\n",
    "    confidence = 1.0 - smoothing + smoothing / classes\n",
    "    label_shape = torch.Size((true_labels.size(0), classes))\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.empty(size=label_shape, dtype=torch.float32, device=true_labels.device)\n",
    "        true_dist.fill_(smoothing / classes)\n",
    "        true_dist.scatter_(1, true_labels.data.unsqueeze(1), confidence)\n",
    "    return true_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, set_length):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths)\n",
    "        \n",
    "#         loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        # apply label smoothing into labels\n",
    "        smooth_label = smooth_one_hot(batch.label, OUTPUT_DIM, smoothing=LABEL_SMOOTHING)\n",
    "        loss = criterion(predictions, smooth_label)\n",
    "        \n",
    "        epoch_acc += (predictions.argmax(1) == smooth_label.argmax(1)).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / set_length, epoch_acc / set_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, set_length):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths)\n",
    "            \n",
    "#             loss = criterion(predictions, batch.label)\n",
    "\n",
    "            # apply label smoothing into labels\n",
    "            smooth_label = smooth_one_hot(batch.label, OUTPUT_DIM, smoothing=LABEL_SMOOTHING)\n",
    "            loss = criterion(predictions, smooth_label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += (predictions.argmax(1) == smooth_label.argmax(1)).sum().item()\n",
    "        \n",
    "    return epoch_loss / set_length, epoch_acc / set_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define epoch time function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00652 | Train Acc: 61.83%\n",
      "\t Val. Loss: 0.00608 |  Val. Acc: 64.24%\n",
      "-----------Total time: 0m 20s\n",
      "Epoch: 02 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00596 | Train Acc: 65.04%\n",
      "\t Val. Loss: 0.00574 |  Val. Acc: 66.37%\n",
      "-----------Total time: 0m 20s\n",
      "Epoch: 03 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00567 | Train Acc: 66.93%\n",
      "\t Val. Loss: 0.00558 |  Val. Acc: 67.24%\n",
      "-----------Total time: 0m 20s\n",
      "Epoch: 04 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00544 | Train Acc: 68.38%\n",
      "\t Val. Loss: 0.00544 |  Val. Acc: 68.04%\n",
      "-----------Total time: 0m 20s\n",
      "Epoch: 05 | Epoch Time: 0m 17s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00520 | Train Acc: 69.97%\n",
      "\t Val. Loss: 0.00537 |  Val. Acc: 68.42%\n",
      "-----------Total time: 0m 21s\n",
      "Epoch: 06 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00501 | Train Acc: 71.30%\n",
      "\t Val. Loss: 0.00541 |  Val. Acc: 68.42%\n",
      "-----------Total time: 0m 16s\n",
      "Epoch: 07 | Epoch Time: 0m 17s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00482 | Train Acc: 72.50%\n",
      "\t Val. Loss: 0.00536 |  Val. Acc: 68.79%\n",
      "-----------Total time: 0m 21s\n",
      "Epoch: 08 | Epoch Time: 0m 17s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00466 | Train Acc: 73.51%\n",
      "\t Val. Loss: 0.00532 |  Val. Acc: 69.24%\n",
      "-----------Total time: 0m 21s\n",
      "Epoch: 09 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00450 | Train Acc: 74.56%\n",
      "\t Val. Loss: 0.00527 |  Val. Acc: 69.37%\n",
      "-----------Total time: 0m 20s\n",
      "Epoch: 10 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00435 | Train Acc: 75.57%\n",
      "\t Val. Loss: 0.00541 |  Val. Acc: 69.37%\n",
      "-----------Total time: 0m 16s\n",
      "Epoch: 11 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00419 | Train Acc: 76.53%\n",
      "\t Val. Loss: 0.00555 |  Val. Acc: 68.83%\n",
      "-----------Total time: 0m 16s\n",
      "Epoch: 12 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00404 | Train Acc: 77.49%\n",
      "\t Val. Loss: 0.00543 |  Val. Acc: 68.95%\n",
      "-----------Total time: 0m 16s\n",
      "Epoch: 13 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00389 | Train Acc: 78.59%\n",
      "\t Val. Loss: 0.00557 |  Val. Acc: 69.06%\n",
      "-----------Total time: 0m 16s\n",
      "Epoch: 14 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00373 | Train Acc: 79.55%\n",
      "\t Val. Loss: 0.00560 |  Val. Acc: 69.15%\n",
      "-----------Total time: 0m 16s\n",
      "Epoch: 15 | Epoch Time: 0m 17s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00357 | Train Acc: 80.48%\n",
      "\t Val. Loss: 0.00577 |  Val. Acc: 68.19%\n",
      "-----------Total time: 0m 17s\n",
      "Epoch: 16 | Epoch Time: 0m 17s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00341 | Train Acc: 81.60%\n",
      "\t Val. Loss: 0.00593 |  Val. Acc: 67.33%\n",
      "-----------Total time: 0m 17s\n",
      "Epoch: 17 | Epoch Time: 0m 16s | Learning rate: 0.0005\n",
      "\tTrain Loss: 0.00325 | Train Acc: 82.63%\n",
      "\t Val. Loss: 0.00617 |  Val. Acc: 67.62%\n",
      "-----------Total time: 0m 16s\n"
     ]
    }
   ],
   "source": [
    "# best_valid_loss = float('inf')\n",
    "best_valid_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "# For splotting\n",
    "all_train_losses = []\n",
    "all_valid_losses = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, len(train_data))\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, len(valid_data))\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "    if valid_acc > best_valid_acc:\n",
    "#         best_valid_loss = valid_loss\n",
    "        best_valid_acc = valid_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), saved_models_path + MODEL_SAVE_FILE)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s | Learning rate: {scheduler.get_lr()[0]}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    all_train_losses.append(train_loss)\n",
    "    all_valid_losses.append(valid_loss)\n",
    "    \n",
    "    # Step up scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Calculate total time\n",
    "    total_time = time.time()\n",
    "    total_mins, total_secs = epoch_time(start_time, total_time)\n",
    "    print(f'-----------Total time: {total_mins}m {total_secs}s')\n",
    "    \n",
    "print(f'Best epoch: {best_epoch+1:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "# plt.xticks(range(0, 10))\n",
    "plt.plot(all_train_losses)\n",
    "plt.plot(all_valid_losses)\n",
    "plt.axvline(x=best_epoch, color='green')\n",
    "\n",
    "plt.legend(['train loss', 'valid loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 10\n"
     ]
    }
   ],
   "source": [
    "print(f'Best epoch: {best_epoch+1:02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00690 | Test Acc: 69.13%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, len(test_data))\n",
    "\n",
    "print(f'Test Loss: {test_loss:.5f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reevaluate on valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.00687 | Test Acc: 69.35%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE))\n",
    "\n",
    "valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, len(valid_data))\n",
    "\n",
    "print(f'Test Loss: {valid_loss:.5f} | Test Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Kaggle Dataset and create submittion file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the model target file\n",
    "MODEL_SAVE_FILE_TARGET = 'LSTM_with_attention_embedding_in_model_origin.pt'\n",
    "\n",
    "def predict_kaggle_test(model, iterator):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths)\n",
    "            \n",
    "            predictions = predictions.argmax(1)\n",
    "            \n",
    "            for i in range(len(batch)):\n",
    "                result.append([batch.id[0][i].item(), [batch.phrase_id[0][i].item(), predictions[i].item()]] )\n",
    "    \n",
    "    result.sort(key = lambda val: val[0])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, [156061, 2]],\n",
       " [1, [156062, 2]],\n",
       " [2, [156063, 2]],\n",
       " [3, [156064, 2]],\n",
       " [4, [156065, 3]],\n",
       " [5, [156066, 3]],\n",
       " [6, [156067, 3]],\n",
       " [7, [156068, 2]],\n",
       " [8, [156069, 3]],\n",
       " [9, [156070, 2]]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE_TARGET))\n",
    "\n",
    "kaggle_result_list = predict_kaggle_test(model, kaggle_test_iterator)\n",
    "\n",
    "kaggle_result_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[66282, [222343, 1]],\n",
       " [66283, [222344, 2]],\n",
       " [66284, [222345, 2]],\n",
       " [66285, [222346, 2]],\n",
       " [66286, [222347, 2]],\n",
       " [66287, [222348, 1]],\n",
       " [66288, [222349, 1]],\n",
       " [66289, [222350, 1]],\n",
       " [66290, [222351, 1]],\n",
       " [66291, [222352, 1]]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_result_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kaggle_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, xxmaj, an, xxeos]</td>\n",
       "      <td>[2, 7, 26, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156066</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but</td>\n",
       "      <td>68</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, xxeos]</td>\n",
       "      <td>[2, 2606, 1723, 30, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156067</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing</td>\n",
       "      <td>2</td>\n",
       "      <td>[xxbos, intermittently, pleasing, xxeos]</td>\n",
       "      <td>[2, 2606, 1723, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156068</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently</td>\n",
       "      <td>65</td>\n",
       "      <td>[xxbos, intermittently, xxeos]</td>\n",
       "      <td>[2, 2606, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156069</td>\n",
       "      <td>8545</td>\n",
       "      <td>pleasing</td>\n",
       "      <td>9</td>\n",
       "      <td>[xxbos, pleasing, xxeos]</td>\n",
       "      <td>[2, 1723, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>8545</td>\n",
       "      <td>but</td>\n",
       "      <td>55</td>\n",
       "      <td>[xxbos, but, xxeos]</td>\n",
       "      <td>[2, 30, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "5    156066        8545                        intermittently pleasing but   \n",
       "6    156067        8545                            intermittently pleasing   \n",
       "7    156068        8545                                     intermittently   \n",
       "8    156069        8545                                           pleasing   \n",
       "9    156070        8545                                                but   \n",
       "\n",
       "   Phrase_length                                   Tokenized_phrase  \\\n",
       "0            188  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "1             77  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "2              8                          [xxbos, xxmaj, an, xxeos]   \n",
       "3              1  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "4              6  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "5             68      [xxbos, intermittently, pleasing, but, xxeos]   \n",
       "6              2           [xxbos, intermittently, pleasing, xxeos]   \n",
       "7             65                     [xxbos, intermittently, xxeos]   \n",
       "8              9                           [xxbos, pleasing, xxeos]   \n",
       "9             55                                [xxbos, but, xxeos]   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]  \n",
       "1      [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "2                                      [2, 7, 26, 3]  \n",
       "3             [2, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "4                  [2, 2606, 1723, 30, 632, 1041, 3]  \n",
       "5                             [2, 2606, 1723, 30, 3]  \n",
       "6                                 [2, 2606, 1723, 3]  \n",
       "7                                       [2, 2606, 3]  \n",
       "8                                       [2, 1723, 3]  \n",
       "9                                         [2, 30, 3]  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_EXTENSION = '.submit.csv'\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(saved_models_path + MODEL_SAVE_FILE_TARGET + CSV_EXTENSION, mode='w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    csv_writer.writerow(['PhraseId', 'Sentiment'])\n",
    "    \n",
    "    for i in range(len(kaggle_result_list)):\n",
    "        csv_writer.writerow(kaggle_result_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
