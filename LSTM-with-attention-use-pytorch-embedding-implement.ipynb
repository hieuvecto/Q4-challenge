{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load config and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import spacy, pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import random\n",
    "import inspect\n",
    "\n",
    "# Custom impport\n",
    "from common.common_classes import TensorField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.tsv', 'GRU-with-attention-implement.ipynb', 'LSTM-with-attention-implement.ipynb', 'prepare-word-embedding-nlp.ipynb', 'LSTM-with-attention-use-pytorch-embedding-implement.ipynb', 'tokenization.ipynb', 'test-batching-padding.ipynb', 'train.tsv', 'test-batching-padding-ok.ipynb', 'LSTM-implement.ipynb', 'sampleSubmission.csv', 'save_data', '.ipynb_checkpoints', '__init__.py', 'README.md', 'generate-result-for-report.ipynb', '.gitignore', '.git', 'common', 'simple-GRU-implement.ipynb']\n"
     ]
    }
   ],
   "source": [
    "path = \"./\"\n",
    "save_data_path = path + 'save_data/'\n",
    "large_save_data_path = '/notebooks/large-storage/'\n",
    "saved_models_path = '/notebooks/large-storage/saved-models/'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = pickle.load(open(save_data_path + 'pre-processed-data.pkl', 'rb'))\n",
    "loaded_kaggle_test = pickle.load(open(save_data_path + 'pre-processed-kaggle-test.pkl', 'rb'))\n",
    "loaded_vocab = pickle.load(open(save_data_path + 'genereated-vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, a, series, of, escapades, demonstratin...</td>\n",
       "      <td>[2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, a, series, of, escapades, demonstratin...</td>\n",
       "      <td>[2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, a, series, xxeos]</td>\n",
       "      <td>[2, 10, 341, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, a, xxeos]</td>\n",
       "      <td>[2, 10, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, series, xxeos]</td>\n",
       "      <td>[2, 341, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  Phrase_length  \\\n",
       "0          1            188   \n",
       "1          2             77   \n",
       "2          2              8   \n",
       "3          2              1   \n",
       "4          2              6   \n",
       "\n",
       "                                    Tokenized_phrase  \\\n",
       "0  [xxbos, a, series, of, escapades, demonstratin...   \n",
       "1  [xxbos, a, series, of, escapades, demonstratin...   \n",
       "2                          [xxbos, a, series, xxeos]   \n",
       "3                                  [xxbos, a, xxeos]   \n",
       "4                             [xxbos, series, xxeos]   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...  \n",
       "1  [2, 10, 341, 11, 14246, 6044, 8, 6604, 19, 64,...  \n",
       "2                                    [2, 10, 341, 3]  \n",
       "3                                         [2, 10, 3]  \n",
       "4                                        [2, 341, 3]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, xxmaj, an, xxeos]</td>\n",
       "      <td>[2, 7, 26, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "\n",
       "   Phrase_length                                   Tokenized_phrase  \\\n",
       "0            188  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "1             77  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "2              8                          [xxbos, xxmaj, an, xxeos]   \n",
       "3              1  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "4              6  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]  \n",
       "1      [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "2                                      [2, 7, 26, 3]  \n",
       "3             [2, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "4                  [2, 2606, 1723, 30, 632, 1041, 3]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = \"xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj\".split()\n",
    "\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]\n",
    "\n",
    "MAX_LABEL = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check max length of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "43802\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_index = -1\n",
    "for i in range(len(loaded_data['Tokenized_phrase'])):\n",
    "    if len(loaded_data['Tokenized_phrase'][i]) > max_len:\n",
    "        max_len = len(loaded_data['Tokenized_phrase'][i])\n",
    "        max_index = i\n",
    "        \n",
    "print(max_len)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "35146\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_index = -1\n",
    "for i in range(len(loaded_kaggle_test['Tokenized_phrase'])):\n",
    "    if len(loaded_kaggle_test['Tokenized_phrase'][i]) > max_len:\n",
    "        max_len = len(loaded_kaggle_test['Tokenized_phrase'][i])\n",
    "        max_index = i\n",
    "        \n",
    "print(max_len)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Encoding and prepraing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(large_save_data_path + 'process-spacy-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0.,\n",
       "       0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[BOS].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp.vocab.get_vector('test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(890280, 308)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test assigning pytorch embedding with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "embed_weights = torch.tensor(nlp.vocab.vectors.data, dtype=torch.float32)\n",
    "embed_layer = nn.Embedding.from_pretrained(embed_weights, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5439657043933447811\n",
      "row: 1081\n"
     ]
    }
   ],
   "source": [
    "cat_id = nlp.vocab.strings[u'cat']\n",
    "print(f\"ID: {cat_id}\")\n",
    "cat_row = nlp.vocab.vectors.key2row[cat_id]\n",
    "print(f\"row: {cat_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector: [-0.15067   -0.024468  -0.23368   -0.23378   -0.18382    0.32711\n",
      " -0.22084   -0.28777    0.12759    1.1656    -0.64163   -0.098455\n",
      " -0.62397    0.010431  -0.25653    0.31799    0.037779   1.1904\n",
      " -0.17714   -0.2595    -0.31461    0.038825  -0.15713   -0.13484\n",
      "  0.36936   -0.30562   -0.40619   -0.38965    0.3686     0.013963\n",
      " -0.6895     0.004066  -0.1367     0.32564    0.24688   -0.14011\n",
      "  0.53889   -0.80441   -0.1777    -0.12922    0.16303    0.14917\n",
      " -0.068429  -0.33922    0.18495   -0.082544  -0.46892    0.39581\n",
      " -0.13742   -0.35132    0.22223   -0.144     -0.048287   0.3379\n",
      " -0.31916    0.20526    0.098624  -0.23877    0.045338   0.43941\n",
      "  0.030385  -0.013821  -0.093273  -0.18178    0.19438   -0.3782\n",
      "  0.70144    0.16236    0.0059111  0.024898  -0.13613   -0.11425\n",
      " -0.31598   -0.14209    0.028194   0.5419    -0.42413   -0.599\n",
      "  0.24976   -0.27003    0.14964    0.29287   -0.31281    0.16543\n",
      " -0.21045   -0.4408     1.2174     0.51236    0.56209    0.14131\n",
      "  0.092514   0.71396   -0.021051  -0.33704   -0.20275   -0.36181\n",
      "  0.22055   -0.25665    0.28425   -0.16968    0.058029   0.61182\n",
      "  0.31576   -0.079185   0.35538   -0.51236    0.4235    -0.30033\n",
      " -0.22376    0.15223   -0.048292   0.23532    0.46507   -0.67579\n",
      " -0.32905    0.08446   -0.22123   -0.045333   0.34463   -0.1455\n",
      " -0.18047   -0.17887    0.96879   -1.0028    -0.47343    0.28542\n",
      "  0.56382   -0.33211   -0.38275   -0.2749    -0.22955   -0.24265\n",
      " -0.37689    0.24822    0.36941    0.14651   -0.37864    0.31134\n",
      " -0.28449    0.36948   -2.8174    -0.38319   -0.022373   0.56376\n",
      "  0.40131   -0.42131   -0.11311   -0.17317    0.1411    -0.13194\n",
      "  0.18494    0.097692  -0.097341  -0.23987    0.16631   -0.28556\n",
      "  0.0038654  0.53292   -0.32367   -0.38744    0.27011   -0.34181\n",
      " -0.27702   -0.67279   -0.10771   -0.062189  -0.24783   -0.070884\n",
      " -0.20898    0.062404   0.022372   0.13408    0.1305    -0.19546\n",
      " -0.46849    0.77731   -0.043978   0.3827    -0.23376    1.0457\n",
      " -0.14371   -0.3565    -0.080713  -0.31047   -0.57822   -0.28067\n",
      " -0.069678   0.068929  -0.16227   -0.63934   -0.62149    0.11222\n",
      " -0.16969   -0.54637    0.49661    0.46565    0.088294  -0.48496\n",
      "  0.69263   -0.068977  -0.53709    0.20802   -0.42987   -0.11921\n",
      "  0.1174    -0.18443    0.43797   -0.1236     0.3607    -0.19608\n",
      " -0.35366    0.18808   -0.5061     0.14455   -0.024368  -0.10772\n",
      " -0.0115     0.58634   -0.054461   0.0076487 -0.056297   0.27193\n",
      "  0.23096   -0.29296   -0.24325    0.10317   -0.10014    0.7089\n",
      "  0.17402   -0.0037509 -0.46304    0.11806   -0.16457   -0.38609\n",
      "  0.14524    0.098122  -0.12352   -0.1047     0.39047   -0.3063\n",
      " -0.65375   -0.0044248 -0.033876   0.037114  -0.27472    0.0053147\n",
      "  0.30737    0.12528   -0.19527   -0.16461    0.087518  -0.051107\n",
      " -0.16323    0.521      0.10822   -0.060379  -0.71735   -0.064327\n",
      "  0.37043   -0.41054   -0.2728    -0.30217    0.015771  -0.43056\n",
      "  0.35647    0.17188   -0.54598   -0.21541   -0.044889  -0.10597\n",
      " -0.54391    0.53908    0.070938   0.097839   0.097908   0.17805\n",
      "  0.18995    0.49962   -0.18529    0.051234   0.019574   0.24805\n",
      "  0.3144    -0.29304    0.54235    0.46672    0.26017   -0.44705\n",
      "  0.28287   -0.033345  -0.33181   -0.10902   -0.023324   0.2106\n",
      " -0.29633    0.81506    0.038524   0.46004    0.17187   -0.29804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.       ]\n",
      "embedding: tensor([[-0.1507, -0.0245, -0.2337, -0.2338, -0.1838,  0.3271, -0.2208, -0.2878,\n",
      "          0.1276,  1.1656, -0.6416, -0.0985, -0.6240,  0.0104, -0.2565,  0.3180,\n",
      "          0.0378,  1.1904, -0.1771, -0.2595, -0.3146,  0.0388, -0.1571, -0.1348,\n",
      "          0.3694, -0.3056, -0.4062, -0.3896,  0.3686,  0.0140, -0.6895,  0.0041,\n",
      "         -0.1367,  0.3256,  0.2469, -0.1401,  0.5389, -0.8044, -0.1777, -0.1292,\n",
      "          0.1630,  0.1492, -0.0684, -0.3392,  0.1849, -0.0825, -0.4689,  0.3958,\n",
      "         -0.1374, -0.3513,  0.2222, -0.1440, -0.0483,  0.3379, -0.3192,  0.2053,\n",
      "          0.0986, -0.2388,  0.0453,  0.4394,  0.0304, -0.0138, -0.0933, -0.1818,\n",
      "          0.1944, -0.3782,  0.7014,  0.1624,  0.0059,  0.0249, -0.1361, -0.1142,\n",
      "         -0.3160, -0.1421,  0.0282,  0.5419, -0.4241, -0.5990,  0.2498, -0.2700,\n",
      "          0.1496,  0.2929, -0.3128,  0.1654, -0.2104, -0.4408,  1.2174,  0.5124,\n",
      "          0.5621,  0.1413,  0.0925,  0.7140, -0.0211, -0.3370, -0.2027, -0.3618,\n",
      "          0.2206, -0.2567,  0.2842, -0.1697,  0.0580,  0.6118,  0.3158, -0.0792,\n",
      "          0.3554, -0.5124,  0.4235, -0.3003, -0.2238,  0.1522, -0.0483,  0.2353,\n",
      "          0.4651, -0.6758, -0.3291,  0.0845, -0.2212, -0.0453,  0.3446, -0.1455,\n",
      "         -0.1805, -0.1789,  0.9688, -1.0028, -0.4734,  0.2854,  0.5638, -0.3321,\n",
      "         -0.3828, -0.2749, -0.2296, -0.2427, -0.3769,  0.2482,  0.3694,  0.1465,\n",
      "         -0.3786,  0.3113, -0.2845,  0.3695, -2.8174, -0.3832, -0.0224,  0.5638,\n",
      "          0.4013, -0.4213, -0.1131, -0.1732,  0.1411, -0.1319,  0.1849,  0.0977,\n",
      "         -0.0973, -0.2399,  0.1663, -0.2856,  0.0039,  0.5329, -0.3237, -0.3874,\n",
      "          0.2701, -0.3418, -0.2770, -0.6728, -0.1077, -0.0622, -0.2478, -0.0709,\n",
      "         -0.2090,  0.0624,  0.0224,  0.1341,  0.1305, -0.1955, -0.4685,  0.7773,\n",
      "         -0.0440,  0.3827, -0.2338,  1.0457, -0.1437, -0.3565, -0.0807, -0.3105,\n",
      "         -0.5782, -0.2807, -0.0697,  0.0689, -0.1623, -0.6393, -0.6215,  0.1122,\n",
      "         -0.1697, -0.5464,  0.4966,  0.4656,  0.0883, -0.4850,  0.6926, -0.0690,\n",
      "         -0.5371,  0.2080, -0.4299, -0.1192,  0.1174, -0.1844,  0.4380, -0.1236,\n",
      "          0.3607, -0.1961, -0.3537,  0.1881, -0.5061,  0.1445, -0.0244, -0.1077,\n",
      "         -0.0115,  0.5863, -0.0545,  0.0076, -0.0563,  0.2719,  0.2310, -0.2930,\n",
      "         -0.2432,  0.1032, -0.1001,  0.7089,  0.1740, -0.0038, -0.4630,  0.1181,\n",
      "         -0.1646, -0.3861,  0.1452,  0.0981, -0.1235, -0.1047,  0.3905, -0.3063,\n",
      "         -0.6538, -0.0044, -0.0339,  0.0371, -0.2747,  0.0053,  0.3074,  0.1253,\n",
      "         -0.1953, -0.1646,  0.0875, -0.0511, -0.1632,  0.5210,  0.1082, -0.0604,\n",
      "         -0.7174, -0.0643,  0.3704, -0.4105, -0.2728, -0.3022,  0.0158, -0.4306,\n",
      "          0.3565,  0.1719, -0.5460, -0.2154, -0.0449, -0.1060, -0.5439,  0.5391,\n",
      "          0.0709,  0.0978,  0.0979,  0.1780,  0.1900,  0.4996, -0.1853,  0.0512,\n",
      "          0.0196,  0.2481,  0.3144, -0.2930,  0.5423,  0.4667,  0.2602, -0.4471,\n",
      "          0.2829, -0.0333, -0.3318, -0.1090, -0.0233,  0.2106, -0.2963,  0.8151,\n",
      "          0.0385,  0.4600,  0.1719, -0.2980,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# cat_embedding is a Tensor representation of cat_vector\n",
    "cat_vector = nlp.vocab.vectors[cat_id]\n",
    "print(f\"vector: {cat_vector}\")\n",
    "cat_embedding = embed_layer(torch.LongTensor([cat_row]))\n",
    "print(f\"embedding: {cat_embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_embedding.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([890280, 308])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_layer.weight.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15321870174910142188\n",
      "row: 684831\n"
     ]
    }
   ],
   "source": [
    "pad_id = nlp.vocab.strings[PAD]\n",
    "print(f\"ID: {pad_id}\")\n",
    "pad_row = nlp.vocab.vectors.key2row[pad_id]\n",
    "print(f\"row: {pad_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle Train dataset\n",
    "PHRASE_ID = data.Field(use_vocab = False)\n",
    "TEXT = TensorField(include_lengths = True, use_vocab = False, sequential = False, pad_token = pad_row)\n",
    "LABEL = data.LabelField(use_vocab = False, dtype=torch.long)\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "ID_TEST = data.Field(use_vocab = False)\n",
    "PHRASE_ID_TEST = data.Field(use_vocab = False)\n",
    "TEXT_TEST = TensorField(include_lengths = True, use_vocab = False, sequential = False, pad_token = pad_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle Train dataset\n",
    "fields = [('id', PHRASE_ID), ('text', TEXT), ('label', LABEL)]\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "fields_test = [('id', ID_TEST), ('phrase_id', PHRASE_ID_TEST), ('text', TEXT_TEST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_data['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_kaggle_test['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_rown: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7f5946881d68>,\n",
       " <torchtext.data.example.Example at 0x7f5946881da0>,\n",
       " <torchtext.data.example.Example at 0x7f5946881dd8>,\n",
       " <torchtext.data.example.Example at 0x7f5946881e10>,\n",
       " <torchtext.data.example.Example at 0x7f5946881e48>,\n",
       " <torchtext.data.example.Example at 0x7f5946881e80>,\n",
       " <torchtext.data.example.Example at 0x7f5946881eb8>,\n",
       " <torchtext.data.example.Example at 0x7f5946881ef0>,\n",
       " <torchtext.data.example.Example at 0x7f5946881f28>,\n",
       " <torchtext.data.example.Example at 0x7f5946881f60>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unknown row\n",
    "unknown_id = nlp.vocab.strings[UNK]\n",
    "unknown_row = nlp.vocab.vectors.key2row[unknown_id]\n",
    "print(f\"unknown_rown: {unknown_row}\")\n",
    "\n",
    "# For Kaggle Train dataset\n",
    "examples = []\n",
    "length = len(loaded_data['Phrase'])\n",
    "for i in range(length):\n",
    "    indexes = []\n",
    "    for j in range(len(loaded_data['Tokenized_phrase'][i])):\n",
    "        if nlp.vocab.has_vector(loaded_data['Tokenized_phrase'][i][j]):\n",
    "            token_id = nlp.vocab.strings[loaded_data['Tokenized_phrase'][i][j]]\n",
    "            token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "\n",
    "            indexes.append(token_row)\n",
    "        else:\n",
    "            indexes.append(unknown_row)\n",
    "    \n",
    "    examples.append(data.Example.fromlist([ [loaded_data['PhraseId'][i]], indexes, loaded_data['Sentiment'][i]], fields))\n",
    "    \n",
    "examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_rown: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torchtext.data.example.Example at 0x7f58b1f78b00>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78b38>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78ba8>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78be0>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78c18>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78c50>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78c88>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78cc0>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78cf8>,\n",
       " <torchtext.data.example.Example at 0x7f58b1f78d30>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unknown row\n",
    "unknown_id = nlp.vocab.strings[UNK]\n",
    "unknown_row = nlp.vocab.vectors.key2row[unknown_id]\n",
    "print(f\"unknown_rown: {unknown_row}\")\n",
    "\n",
    "# For Kaggle Test dataset\n",
    "examples_test = []\n",
    "length = len(loaded_kaggle_test['Phrase'])\n",
    "for i in range(length):\n",
    "    indexes = []\n",
    "    for j in range(len(loaded_kaggle_test['Tokenized_phrase'][i])):\n",
    "        if nlp.vocab.has_vector(loaded_kaggle_test['Tokenized_phrase'][i][j]):\n",
    "            token_id = nlp.vocab.strings[loaded_kaggle_test['Tokenized_phrase'][i][j]]\n",
    "            token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "            \n",
    "            indexes.append(token_row)\n",
    "        else:\n",
    "            indexes.append(unknown_row)\n",
    "    \n",
    "    examples_test.append(data.Example.fromlist([ [i], [loaded_kaggle_test['PhraseId'][i]], indexes ], fields_test))\n",
    "    \n",
    "examples_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[684832, 6, 684833]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 684833\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings[EOS]\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[684832, 40929, 11176, 29, 737, 3812, 1240, 684833]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_test[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 737\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings['mostly']\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[3].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data.Dataset(examples, fields)\n",
    "data_set_test = data.Dataset(examples_test, fields_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.sort_key = lambda x: len(x.text)\n",
    "data_set_test.sort_key = lambda x: len(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 9131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data_set.split([0.8, 0.1, 0.1], random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sort_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124848"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_set.sort_key = lambda x: len(x.text)\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsource(train_data.sort_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_set_test.sort_key = lambda x: len(x.text)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsource(data_set_test.sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)\n",
    "\n",
    "kaggle_test_iterator = data.BucketIterator(\n",
    "    data_set_test, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_iterator = iter(train_iterator)\n",
    "batch = next(raw_train_iterator)\n",
    "\n",
    "raw_kaggle_test_iterator = iter(kaggle_test_iterator)\n",
    "batch_test = next(raw_kaggle_test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = batch.text\n",
    "\n",
    "c, d = batch_test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 9])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[684832,    200,     63,     90,      6, 333750,      8,  87261, 684833],\n",
       "        [684832,      6,    176,     42,    313,   2358,   4023,   1214, 684833],\n",
       "        [684832,      3,    141,    253,      6,   1889,    498,      2, 684833],\n",
       "        [684832,    205,     56,     45,    181,   2593,   5716,  10983, 684833],\n",
       "        [684832,    622,    891,     13,      3,     99,      2,   1864, 684833],\n",
       "        [684832,     40,      2,    631,    354,      2,  16439,    810, 684833],\n",
       "        [684832,      5,     23,      6, 684837,    186, 684837,  78888, 684833],\n",
       "        [684832,    308,    407,   2325,      3,   2105,      8,   3242, 684833],\n",
       "        [684832,   3868,    362,    495,    169,      3,    226,  33789, 684833],\n",
       "        [684832,   4407,     13,     58,  12745,    239,      8,  12965, 684833],\n",
       "        [684832,  12657,     13,     36,     94,   2996,     36,  60409, 684833],\n",
       "        [684832,     13,   1321,    495,     29,    371,      3,   2181, 684833],\n",
       "        [684832,     11,      2,      5,     75,   1274,     42,    247, 684833],\n",
       "        [684832,     13,      6,   1843,    641,    506,      8,     81, 684833],\n",
       "        [684832,    282,     57,    380,      2,     29,     39,   4727, 684833],\n",
       "        [684832,      6,  11738,      8,    528,     45,  20602,     10, 684833],\n",
       "        [684832,     76,      6,   1695,      2,  87239,    173,      1, 684833],\n",
       "        [684832,    108,     43,      3,  24748,   2957,   1592,    641, 684833],\n",
       "        [684832,    124,    201,     28,    100,     16,      6,    195, 684833],\n",
       "        [684832,  27607,      2, 640808,    569,      7,   4809,   9103, 684833],\n",
       "        [684832,     79,   1270, 684837,  29162, 684837,  29034,   1198, 684833],\n",
       "        [684832,     24,      6, 684837, 660487, 684837,  73780,   1910, 684833],\n",
       "        [684832,      3,    202,    864,     33,    309,     33,  24733, 684833],\n",
       "        [684832,      3,   3233,     42,     93,    227,   2215,    675, 684833],\n",
       "        [684832,     43,     10,     88,     15,    125,    249,    229, 684833],\n",
       "        [684832,      0, 684837,  30655,      7, 684837, 467330,      0, 684833],\n",
       "        [684832,      3,   2175,  13465, 519081,      8, 684837,  15900, 684833],\n",
       "        [684832,     14,   3535,    216,      7,    412,      6,    176, 684833],\n",
       "        [684832,      6,  22996,      2,   2678,     33,    929,    682, 684833],\n",
       "        [684832, 684837,  21149, 684837,  37420,      7,  11662,   3744, 684833],\n",
       "        [684832,     70,    133, 684837,  18291,    208,      5,    229, 684833],\n",
       "        [684832,     76,     28,  11341,      6,    469,     91,   1198, 684833],\n",
       "        [684832,  44940,     75,  28321,   2467,     33,  18160,   2996, 684833],\n",
       "        [684832,      3,  14074, 294749,      8,      3,   2181,   1905, 684833],\n",
       "        [684832,     23,  13370,     60,     13, 684837,  14378,      7, 684833],\n",
       "        [684832, 684837,      7,  21271,     12,    672,   7635,    772, 684833],\n",
       "        [684832,    214,      3,  30324,      8,  86385,      7,  19761, 684833],\n",
       "        [684832,    111,    510,    472,      5,     19,    293,     10, 684833],\n",
       "        [684832, 684837,     37, 684837,      3, 684837,  82364,   1107, 684833],\n",
       "        [684832, 555441,     68,    245,     31,    498,     54,    239, 684833],\n",
       "        [684832,   3289,      5,      3,   1406,     33,   5960,   2274, 684833],\n",
       "        [684832,    238,  11506,    171,    290,     33,   3693,   3289, 684833],\n",
       "        [684832,  53225,     33,    264, 684837,   6391, 684837, 292733, 684833],\n",
       "        [684832,  99259,    136,    121,      3,    915,    111,   7968, 684833],\n",
       "        [684832,      5, 111434,     12,  10228,     24,   1277, 312845, 684833],\n",
       "        [684832,      6,    649,      2,    354,  46898,    898,      1, 684833],\n",
       "        [684832,     12,     14,   2467,  17537,   1681,     42,    202, 684833],\n",
       "        [684832, 684837, 145780,      7, 684837, 174587, 684837, 139289, 684833],\n",
       "        [684832,      5,      3,  51783,    610,     14,  12530,      7, 684833],\n",
       "        [684832, 684837,  21232,    498,   1235,     56,     45,    569, 684833],\n",
       "        [684832,    244,     62,     14,   3477,     16,   1438,      7, 684833],\n",
       "        [684832,      5,    103,      6,    498,     24,    171,   1065, 684833],\n",
       "        [684832,     23,     13,    379,   2158,     80, 684837,   7124, 684833],\n",
       "        [684832, 684837,    334,   2861,    293,    214,   2446,   2639, 684833],\n",
       "        [684832,      3,    346,      8, 684837,   2084, 684837,   2954, 684833],\n",
       "        [684832,   1865,      5,      3,   8866,   4861,   3724,      1, 684833],\n",
       "        [684832,    141,     91,     33,  12351,    354,  29906,   3974, 684833],\n",
       "        [684832,     14,   3908,      5, 684837,   3561, 684837,  11662, 684833],\n",
       "        [684832,     26,      6,   1202,      7,  43402,    449,     74, 684833],\n",
       "        [684832,   7357,      7,    141,  21340,    498,     13,    178, 684833],\n",
       "        [684832,     16, 684837,   1136, 684837, 140557,     14,   1505, 684833],\n",
       "        [684832,     12,     46,     23,    342,     13, 684837,  59542, 684833],\n",
       "        [684832,     14,     28,    112,     94,      8,    194,      1, 684833],\n",
       "        [684832,     11,    157,      5,    541,   5238,    111,   6234, 684833]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 0, 2, 2, 1, 3, 3, 1, 3, 3, 2, 2, 2, 2, 2, 0, 2, 1, 4, 3, 2, 3, 2,\n",
       "        2, 2, 1, 3, 1, 2, 2, 1, 3, 1, 2, 2, 1, 4, 2, 3, 2, 3, 2, 2, 1, 4, 2, 2,\n",
       "        2, 3, 2, 3, 1, 2, 2, 3, 4, 2, 2, 4, 2, 2, 1, 4], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[133918,  57783,  94049,  86671,  84086,  74128, 112683, 126943,  12599,\n",
       "         138419,  47937,  62635, 104584,  86587, 113162,  81036,  62472, 147974,\n",
       "          32209, 133654,  95241, 137072,  66415,  75555,  53039, 130485,  79837,\n",
       "         152257,  39951, 136680, 121126, 102615, 101662, 119728, 108929, 145776,\n",
       "          36689,  66928, 109732, 109843, 130506,  33026, 123268, 155495, 114095,\n",
       "          27453, 122599,  82520,  21535, 104973,  91096,  97182,  84542, 119081,\n",
       "         104435,  65401,  30863, 141808,  39997, 145932,  46149, 125167, 132902,\n",
       "         117864]], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['Sentiment'][17921-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[684832,    858,     37,     10,     14,    117,      5,     23,    191,\n",
       "         684833],\n",
       "        [684832, 684837,     16, 684837, 146405, 684837,  11721,     92,      1,\n",
       "         684833],\n",
       "        [684832,     19,     16,      3,    420,  20523,      8,     85,    711,\n",
       "         684833],\n",
       "        [684832, 130283,      9,     78,    418,    154,     10,     14,   4905,\n",
       "         684833],\n",
       "        [684832, 684837,   4628,     76,      6,    127,      5, 298172,      2,\n",
       "         684833],\n",
       "        [684832,     36,    194,     63,     90,  12832,     13,      6,  24748,\n",
       "         684833],\n",
       "        [684832,   4089,   5529,      7,    588,     33,  34423,   4043,   2809,\n",
       "         684833],\n",
       "        [684832,    171,    227,  43211,      2,  97814,     33,  98296,  15611,\n",
       "         684833],\n",
       "        [684832,      8, 684837,   7078,    213,  36288,     24,    334,     99,\n",
       "         684833],\n",
       "        [684832,  38669,  13120,      8,     51,   8953,     33,   2467,  58039,\n",
       "         684833],\n",
       "        [684832,      6,  49071,   2076,  13327,      7,   2642,    898,      2,\n",
       "         684833],\n",
       "        [684832,  42793,   7635,    772,  43571,   7635,    772,  21192,  15966,\n",
       "         684833],\n",
       "        [684832,  35010,     13,      3,   3770,      8,  33096, 684837,  19642,\n",
       "         684833],\n",
       "        [684832,    216,    983,      5,    100,     10,   1257,     36,   7540,\n",
       "         684833],\n",
       "        [684832, 684837,    254,     39,   1493,   3592,   7049,  38826,  61157,\n",
       "         684833],\n",
       "        [684832,     42,      3,   5915,  75364,      7,  33060,  22935,   1931,\n",
       "         684833],\n",
       "        [684832, 684837,      3, 684837,      0,  15319,  29798,      2,     29,\n",
       "         684833],\n",
       "        [684832, 684837,  20842,     64, 684837, 150812,   2289, 684837,  23085,\n",
       "         684833],\n",
       "        [684832,      2,  44484,      2, 106919,      2,      7,    557,    789,\n",
       "         684833],\n",
       "        [684832,      3,   4337,   1564,   5279, 684837,  84870, 684837,      0,\n",
       "         684833],\n",
       "        [684832,     63,   1195,     90,    106,   2325,   1120,    111,    309,\n",
       "         684833],\n",
       "        [684832,     23,    407, 684837,   2441, 684837,   4623, 684837,  14615,\n",
       "         684833],\n",
       "        [684832, 684837, 138017, 684837, 331965,     14,   1249,  23325,   1716,\n",
       "         684833],\n",
       "        [684832,    126,    132,     33,    187,      2,    569,      7,   3535,\n",
       "         684833],\n",
       "        [684832,     92,    248,     57,      3,   3883,      8,      6,  48980,\n",
       "         684833],\n",
       "        [684832,     35,     25,     15,    100,   4098,     37,     12,    749,\n",
       "         684833],\n",
       "        [684832,    275,    655,      3,    373,      8,      3,   2527, 106382,\n",
       "         684833],\n",
       "        [684832,     24,   1270,    645,  36343,      7,  14416,   2446,  20055,\n",
       "         684833],\n",
       "        [684832,     27,     38,    526,    216,      5,    100,      6,  23700,\n",
       "         684833],\n",
       "        [684832,      9,    111,  17343,   6345, 684837,      3, 684837,   1907,\n",
       "         684833],\n",
       "        [684832,     36,     70,    201,     23,    618,     13,  29399,  41423,\n",
       "         684833],\n",
       "        [684832, 684837,    305,      9,    997,     48,     10,     13,  21183,\n",
       "         684833],\n",
       "        [684832,     80,      3,    257,      8, 684837,  51012, 684837,   2571,\n",
       "         684833],\n",
       "        [684832, 684837,     59,    582,      5, 684837,  15335,   7311,     18,\n",
       "         684833],\n",
       "        [684832, 684837,    377, 684837,  21790,   6456,     13,  29153,  45137,\n",
       "         684833],\n",
       "        [684832,    100,     13,      3,   2486,      8,    208,     69,     91,\n",
       "         684833],\n",
       "        [684832,     65,     11,     15,      6,  17521,    751,    142,      1,\n",
       "         684833],\n",
       "        [684832, 581431,      3,   1198,     57,      3,    126,   1448,     74,\n",
       "         684833],\n",
       "        [684832,     23,      6,     91,    447,     33,    777,    112,    207,\n",
       "         684833],\n",
       "        [684832,      5,   3922,     57,     39,  10914,     72,    449,   2957,\n",
       "         684833],\n",
       "        [684832,    187,    280,      6,    775,   2747,     13,     93,   6291,\n",
       "         684833],\n",
       "        [684832,  20423,    500,    121,     54,   2072,     33,   2400,   3613,\n",
       "         684833],\n",
       "        [684832,   2357,  11236,    451,    111,    868,      5,      3,    910,\n",
       "         684833],\n",
       "        [684832, 684837,     10,  28157,      5,     23,      6,    200,    224,\n",
       "         684833],\n",
       "        [684832,      6,  13897,     13,      6,   5776,     24,    116,  14766,\n",
       "         684833],\n",
       "        [684832,    588,     33,  47452,   7142,  80686,  39375,     33,  39375,\n",
       "         684833],\n",
       "        [684832,     80,   7854,  24495,      3,    996,      8,    404,  43102,\n",
       "         684833],\n",
       "        [684832,      2,    112,   1669,      2,      7,   2845,   1334,      1,\n",
       "         684833],\n",
       "        [684832,     11,  19429,     36,    132,     36,    221,     33,  11053,\n",
       "         684833],\n",
       "        [684832,      6,   4171,      8,  18108, 153540,      7,   4132,  54142,\n",
       "         684833],\n",
       "        [684832,     24, 684837, 177229,     13,  12311,     14, 684837,    940,\n",
       "         684833],\n",
       "        [684832,      8, 684837,   3561,    905,     13,     58,  28836,    110,\n",
       "         684833],\n",
       "        [684832,    235,      3,    498,      6,  21062,      7,   4285,   5720,\n",
       "         684833],\n",
       "        [684832,      9,     71,    633,     31,   5465,     33,  11233,  23961,\n",
       "         684833],\n",
       "        [684832,   1163,   3862,     77,     10,     14,      6,  20276,   1197,\n",
       "         684833],\n",
       "        [684832, 684837,  37903, 684837,  27644,     76,      6,  84051,  19804,\n",
       "         684833],\n",
       "        [684832,      0,     14,    885,      5,   8041,   8630,      7,    356,\n",
       "         684833],\n",
       "        [684832,     26,  80910,   4861,      7,    377,      8,  95862,   2327,\n",
       "         684833],\n",
       "        [684832,      3,  78776,      8,      3,    770,     33,   5742,    610,\n",
       "         684833],\n",
       "        [684832, 684837,     10,     14,   2662, 173886,     51,      3,    110,\n",
       "         684833],\n",
       "        [684832, 684837,    195,      3,   1198,  79457,     42,    190,    373,\n",
       "         684833],\n",
       "        [684832,     12,     97,     79,    245,    688,     60,      3,    332,\n",
       "         684833],\n",
       "        [684832, 684837,      3,   1198,    235,      6,  10348,   1481,     64,\n",
       "         684833],\n",
       "        [684832,      9,     71,     28,    121,      3, 684837,   2687,   4499,\n",
       "         684833]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[47179, 50045, 46462, 44533, 53032, 32955, 11623, 20504, 41241,  8410,\n",
       "          1622,  7377, 56392, 57556, 12486, 25215, 48991,  3850, 42415, 49212,\n",
       "         59154,  2684, 52932, 62381, 26115, 65211, 63658, 28986, 15879, 58026,\n",
       "         27986, 41181, 46849, 18459, 54574, 46478, 58239, 14695, 30341, 25839,\n",
       "         59208, 35617, 58876, 56748, 17563, 58062,  6787, 22929, 23357, 17287,\n",
       "          4608, 27127, 53929, 65272, 51887, 37848,  3149, 32164, 43127, 23021,\n",
       "         64075, 26385, 32284, 37401]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.phrase_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[203240, 206106, 202523, 200594, 209093, 189016, 167684, 176565, 197302,\n",
       "         164471, 157683, 163438, 212453, 213617, 168547, 181276, 205052, 159911,\n",
       "         198476, 205273, 215215, 158745, 208993, 218442, 182176, 221272, 219719,\n",
       "         185047, 171940, 214087, 184047, 197242, 202910, 174520, 210635, 202539,\n",
       "         214300, 170756, 186402, 181900, 215269, 191678, 214937, 212809, 173624,\n",
       "         214123, 162848, 178990, 179418, 173348, 160669, 183188, 209990, 221333,\n",
       "         207948, 193909, 159210, 188225, 199188, 179082, 220136, 182446, 188345,\n",
       "         193462]], device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test.phrase_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId                               205705\n",
       "SentenceId                              10938\n",
       "Phrase                               and then\n",
       "Phrase_length                              38\n",
       "Tokenized_phrase    [xxbos, and, then, xxeos]\n",
       "Indexed_phrase                [2, 12, 320, 3]\n",
       "Name: 49644, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.iloc[49644]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_rown: 98\n"
     ]
    }
   ],
   "source": [
    "# test extracted data\n",
    "token_id = nlp.vocab.strings['then']\n",
    "token_row = nlp.vocab.vectors.key2row[token_id]\n",
    "print(f\"token_rown: {token_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, pretrained_embed_weights, embedding_dim, hidden_dim, context_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, padding_idx=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        assert pretrained_embed_weights.shape[1] == embedding_dim, \\\n",
    "                \"pretrained_embed_weights shape[1] does not match embedding_dim\"\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embed_weights, freeze=True, padding_idx=padding_idx)\n",
    "\n",
    "        self.rnn = nn.LSTM( embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional,\n",
    "                           batch_first=True,\n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        if bidirectional:\n",
    "            ## Word-level hierarchical attention:\n",
    "            self.ui = nn.Linear(2*hidden_dim, context_dim)\n",
    "            self.uw = nn.Parameter(torch.randn(context_dim))\n",
    "            \n",
    "            self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        else:\n",
    "            ## Word-level hierarchical attention:\n",
    "            self.ui = nn.Linear(hidden_dim, context_dim)\n",
    "            self.uw = nn.Parameter(torch.randn(context_d))\n",
    "            \n",
    "            self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent len, embedding_dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        #output = [batch size, senq len, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            ## Word-level hierarchical attention:\n",
    "            u_it = torch.tanh(self.ui(output)) # Batch size X senq len X context dim\n",
    "            weights = torch.softmax(u_it.matmul(self.uw), dim=1).unsqueeze(1)\n",
    "            \n",
    "            hidden = torch.sum(weights.matmul(output), dim=1) # Batch size X Hidden dim*2\n",
    "\n",
    "            hidden = self.dropout(hidden)\n",
    "        else:\n",
    "            u_it = torch.tanh(self.ui(output)) # Batch size X senq len X context dim\n",
    "            weights = torch.softmax(u_it.matmul(self.uw), dim=1).unsqueeze(1)\n",
    "            \n",
    "            hidden = torch.sum(weights.matmul(output), dim=1) # Batch size X Hidden dim\n",
    "\n",
    "            hidden = self.dropout(hidden)\n",
    "        \n",
    "        #if self.bidirectional:\n",
    "        #    hidden = [batch size, hid dim * num directions]\n",
    "        #else:\n",
    "        #    hidden = [batch size, hid dim]\n",
    "        \n",
    "        # with RELU\n",
    "        #return self.fc(self.relu(hidden))\n",
    "        \n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameter and init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_rown: 684831\n"
     ]
    }
   ],
   "source": [
    "# Get padding index\n",
    "pad_id = nlp.vocab.strings[PAD]\n",
    "pad_row = nlp.vocab.vectors.key2row[pad_id]\n",
    "print(f\"pad_rown: {pad_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_EMBED_WEIGHTS = torch.tensor(nlp.vocab.vectors.data, dtype=torch.float32)\n",
    "EMBEDDING_DIM = 308\n",
    "HIDDEN_DIM = 256\n",
    "CONTEXT_DIM = 70\n",
    "OUTPUT_DIM = 5\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "PADDING_IDX=None\n",
    "\n",
    "# Regularization hyperparameter\n",
    "DROPOUT = 0.5\n",
    "L2_LAMBDA = 0 #0.00001\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "N_EPOCHS = 100\n",
    "\n",
    "MODEL_SAVE_FILE = 'LSTM_with_attention_embedding_in_model_origin.pt'\n",
    "model = LSTMWithAttention(PRETRAINED_EMBED_WEIGHTS,\n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            CONTEXT_DIM,\n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT,\n",
    "            PADDING_IDX).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the number of parameters in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,774,673 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, set_length):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        epoch_acc += (predictions.argmax(1) == batch.label).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / set_length, epoch_acc / set_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, set_length):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += (predictions.argmax(1) == batch.label).sum().item()\n",
    "        \n",
    "    return epoch_loss / set_length, epoch_acc / set_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define epoch time function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01439 | Train Acc: 61.96%\n",
      "\t Val. Loss: 0.01347 |  Val. Acc: 64.29%\n",
      "Epoch: 02 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01301 | Train Acc: 65.25%\n",
      "\t Val. Loss: 0.01264 |  Val. Acc: 66.38%\n",
      "Epoch: 03 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01229 | Train Acc: 67.22%\n",
      "\t Val. Loss: 0.01221 |  Val. Acc: 67.71%\n",
      "Epoch: 04 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 0.01168 | Train Acc: 68.90%\n",
      "\t Val. Loss: 0.01195 |  Val. Acc: 68.25%\n",
      "Epoch: 05 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01117 | Train Acc: 70.17%\n",
      "\t Val. Loss: 0.01168 |  Val. Acc: 69.38%\n",
      "Epoch: 06 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01068 | Train Acc: 71.41%\n",
      "\t Val. Loss: 0.01175 |  Val. Acc: 69.52%\n",
      "Epoch: 07 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01035 | Train Acc: 72.44%\n",
      "\t Val. Loss: 0.01169 |  Val. Acc: 69.26%\n",
      "Epoch: 08 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.01000 | Train Acc: 73.20%\n",
      "\t Val. Loss: 0.01161 |  Val. Acc: 70.15%\n",
      "Epoch: 09 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00966 | Train Acc: 74.18%\n",
      "\t Val. Loss: 0.01166 |  Val. Acc: 70.02%\n",
      "Epoch: 10 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00929 | Train Acc: 75.09%\n",
      "\t Val. Loss: 0.01198 |  Val. Acc: 69.73%\n",
      "Epoch: 11 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00893 | Train Acc: 76.13%\n",
      "\t Val. Loss: 0.01236 |  Val. Acc: 69.11%\n",
      "Epoch: 12 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00856 | Train Acc: 77.01%\n",
      "\t Val. Loss: 0.01221 |  Val. Acc: 69.42%\n",
      "Epoch: 13 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00820 | Train Acc: 77.89%\n",
      "\t Val. Loss: 0.01285 |  Val. Acc: 68.51%\n",
      "Epoch: 14 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00779 | Train Acc: 78.92%\n",
      "\t Val. Loss: 0.01309 |  Val. Acc: 68.66%\n",
      "Epoch: 15 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00742 | Train Acc: 79.94%\n",
      "\t Val. Loss: 0.01371 |  Val. Acc: 68.40%\n",
      "Epoch: 16 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00704 | Train Acc: 81.01%\n",
      "\t Val. Loss: 0.01451 |  Val. Acc: 67.89%\n",
      "Epoch: 17 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00665 | Train Acc: 82.10%\n",
      "\t Val. Loss: 0.01525 |  Val. Acc: 67.40%\n",
      "Epoch: 18 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 0.00623 | Train Acc: 83.13%\n",
      "\t Val. Loss: 0.01546 |  Val. Acc: 67.42%\n",
      "Epoch: 19 | Epoch Time: 0m 16s\n",
      "\tTrain Loss: 0.00587 | Train Acc: 84.18%\n",
      "\t Val. Loss: 0.01652 |  Val. Acc: 67.02%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-15332ba96c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-6b206d8692c3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, set_length)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;31m# fast-forward if loaded from state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations_this_epoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36mpool\u001b[0;34m(data, batch_size, key, batch_size_fn, random_shuffler, shuffle, sort_within_batch)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mp_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msort_within_batch\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-f1db29845134>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_set_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# best_valid_loss = float('inf')\n",
    "best_valid_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "# For splotting\n",
    "all_train_losses = []\n",
    "all_valid_losses = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, len(train_data))\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, len(valid_data))\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "    if valid_acc > best_valid_acc:\n",
    "#         best_valid_loss = valid_loss\n",
    "        best_valid_acc = valid_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), saved_models_path + MODEL_SAVE_FILE)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    all_train_losses.append(train_loss)\n",
    "    all_valid_losses.append(valid_loss)\n",
    "    \n",
    "print(f'Best epoch: {best_epoch+1:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "# plt.xticks(range(0, 10))\n",
    "plt.plot(all_train_losses)\n",
    "plt.plot(all_valid_losses)\n",
    "plt.axvline(x=best_epoch, color='green')\n",
    "\n",
    "plt.legend(['train loss', 'valid loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15606"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 08\n"
     ]
    }
   ],
   "source": [
    "print(f'Best epoch: {best_epoch+1:02}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.01165 | Test Acc: 69.35%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, len(test_data))\n",
    "\n",
    "print(f'Test Loss: {test_loss:.5f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reevaluate on valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.01161 | Test Acc: 70.15%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE))\n",
    "\n",
    "valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, len(valid_data))\n",
    "\n",
    "print(f'Test Loss: {valid_loss:.5f} | Test Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Kaggle Dataset and create submittion file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the model target file\n",
    "MODEL_SAVE_FILE_TARGET = 'LSTM_with_attention_embedding_in_model_origin-train-73.20-valid-70.15.pt'\n",
    "\n",
    "def predict_kaggle_test(model, iterator):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths)\n",
    "            \n",
    "            predictions = predictions.argmax(1)\n",
    "            \n",
    "            for i in range(len(batch)):\n",
    "                result.append([batch.id[0][i].item(), [batch.phrase_id[0][i].item(), predictions[i].item()]] )\n",
    "    \n",
    "    result.sort(key = lambda val: val[0])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, [156061, 3]],\n",
       " [1, [156062, 2]],\n",
       " [2, [156063, 2]],\n",
       " [3, [156064, 2]],\n",
       " [4, [156065, 2]],\n",
       " [5, [156066, 3]],\n",
       " [6, [156067, 3]],\n",
       " [7, [156068, 2]],\n",
       " [8, [156069, 3]],\n",
       " [9, [156070, 2]]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(saved_models_path + MODEL_SAVE_FILE_TARGET))\n",
    "\n",
    "kaggle_result_list = predict_kaggle_test(model, kaggle_test_iterator)\n",
    "\n",
    "kaggle_result_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[66282, [222343, 2]],\n",
       " [66283, [222344, 2]],\n",
       " [66284, [222345, 2]],\n",
       " [66285, [222346, 2]],\n",
       " [66286, [222347, 2]],\n",
       " [66287, [222348, 0]],\n",
       " [66288, [222349, 1]],\n",
       " [66289, [222350, 1]],\n",
       " [66290, [222351, 1]],\n",
       " [66291, [222352, 1]]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_result_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kaggle_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Phrase_length</th>\n",
       "      <th>Tokenized_phrase</th>\n",
       "      <th>Indexed_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>188</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>77</td>\n",
       "      <td>[xxbos, xxmaj, an, intermittently, pleasing, b...</td>\n",
       "      <td>[2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>8</td>\n",
       "      <td>[xxbos, xxmaj, an, xxeos]</td>\n",
       "      <td>[2, 7, 26, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>1</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 409, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>6</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, mostly,...</td>\n",
       "      <td>[2, 2606, 1723, 30, 632, 1041, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156066</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but</td>\n",
       "      <td>68</td>\n",
       "      <td>[xxbos, intermittently, pleasing, but, xxeos]</td>\n",
       "      <td>[2, 2606, 1723, 30, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156067</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing</td>\n",
       "      <td>2</td>\n",
       "      <td>[xxbos, intermittently, pleasing, xxeos]</td>\n",
       "      <td>[2, 2606, 1723, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156068</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently</td>\n",
       "      <td>65</td>\n",
       "      <td>[xxbos, intermittently, xxeos]</td>\n",
       "      <td>[2, 2606, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156069</td>\n",
       "      <td>8545</td>\n",
       "      <td>pleasing</td>\n",
       "      <td>9</td>\n",
       "      <td>[xxbos, pleasing, xxeos]</td>\n",
       "      <td>[2, 1723, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>8545</td>\n",
       "      <td>but</td>\n",
       "      <td>55</td>\n",
       "      <td>[xxbos, but, xxeos]</td>\n",
       "      <td>[2, 30, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "5    156066        8545                        intermittently pleasing but   \n",
       "6    156067        8545                            intermittently pleasing   \n",
       "7    156068        8545                                     intermittently   \n",
       "8    156069        8545                                           pleasing   \n",
       "9    156070        8545                                                but   \n",
       "\n",
       "   Phrase_length                                   Tokenized_phrase  \\\n",
       "0            188  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "1             77  [xxbos, xxmaj, an, intermittently, pleasing, b...   \n",
       "2              8                          [xxbos, xxmaj, an, xxeos]   \n",
       "3              1  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "4              6  [xxbos, intermittently, pleasing, but, mostly,...   \n",
       "5             68      [xxbos, intermittently, pleasing, but, xxeos]   \n",
       "6              2           [xxbos, intermittently, pleasing, xxeos]   \n",
       "7             65                     [xxbos, intermittently, xxeos]   \n",
       "8              9                           [xxbos, pleasing, xxeos]   \n",
       "9             55                                [xxbos, but, xxeos]   \n",
       "\n",
       "                                      Indexed_phrase  \n",
       "0  [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 15, 3]  \n",
       "1      [2, 7, 26, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "2                                      [2, 7, 26, 3]  \n",
       "3             [2, 2606, 1723, 30, 632, 1041, 409, 3]  \n",
       "4                  [2, 2606, 1723, 30, 632, 1041, 3]  \n",
       "5                             [2, 2606, 1723, 30, 3]  \n",
       "6                                 [2, 2606, 1723, 3]  \n",
       "7                                       [2, 2606, 3]  \n",
       "8                                       [2, 1723, 3]  \n",
       "9                                         [2, 30, 3]  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_kaggle_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_EXTENSION = '.submit.csv'\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(saved_models_path + MODEL_SAVE_FILE_TARGET + CSV_EXTENSION, mode='w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    csv_writer.writerow(['PhraseId', 'Sentiment'])\n",
    "    \n",
    "    for i in range(len(kaggle_result_list)):\n",
    "        csv_writer.writerow(kaggle_result_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
